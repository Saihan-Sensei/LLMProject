{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8e0eab0-25ae-4a2b-82e1-6f2ff13abd85",
   "metadata": {},
   "source": [
    "# Second Trial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f4973a-c38f-427d-8aa0-c39620e09746",
   "metadata": {},
   "source": [
    "## .npy -> .json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "198dc138-32b7-48cf-a5b4-e1d0fb5716c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Conversion complete! JSON saved as emg_all_emotions_sharegpt.json\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "parent_dir = \"/home/saihan/data\"\n",
    "\n",
    "sharegpt_data = []\n",
    "for emotion_label in os.listdir(parent_dir):\n",
    "    folder_path = os.path.join(parent_dir, emotion_label)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".npy\"):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "            try:\n",
    "                features = np.load(file_path)\n",
    "                for feature_vector in features:\n",
    "                    feature_str = \", \".join([f\"Feature {j+1} = {val:.2E}\" for j, val in enumerate(feature_vector)])\n",
    "                    sharegpt_data.append({\n",
    "                        \"conversations\": [\n",
    "                            {\"from\": \"user\", \"value\": f\"EMG features: {feature_str}\"},\n",
    "                            {\"from\": \"assistant\", \"value\": f\"Emotion: {emotion_label.capitalize()}\"}\n",
    "                        ]\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {file_path}: {e}\")\n",
    "\n",
    "output_path = \"emg_all_emotions_sharegpt.json\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(sharegpt_data, f, indent=4)\n",
    "\n",
    "print(f\" Conversion complete! JSON saved as {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24780892-73f9-4897-954e-868da998b47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saihan/miniconda3/envs/unsloth/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.50.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3050 Laptop GPU. Num GPUs = 1. Max memory: 4.0 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
    "fourbit_models = [\n",
    "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 2x faster\n",
    "    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
    "    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
    "    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # 4bit for 405b!\n",
    "    \"unsloth/Mistral-Small-Instruct-2409\",     # Mistral 22b 2x faster!\n",
    "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
    "    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n",
    "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
    "    \"unsloth/gemma-2-9b-bnb-4bit\",\n",
    "    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n",
    "\n",
    "    \"unsloth/Llama-3.2-1B-bnb-4bit\",           # NEW! Llama 3.2 models\n",
    "    \"unsloth/Llama-3.2-1B-Instruct-bnb-4bit\",\n",
    "    \"unsloth/Llama-3.2-3B-bnb-4bit\",\n",
    "    \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\",\n",
    "\n",
    "    \"unsloth/Llama-3.3-70B-Instruct-bnb-4bit\" # NEW! Llama 3.3 70B!\n",
    "] # More models at https://huggingface.co/unsloth\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Llama-3.2-3B-Instruct\", # or choose \"unsloth/Llama-3.2-1B-Instruct\"\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc4ed1cd-3a60-492a-b7be-9fe623f5fee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading numpy-2.2.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Downloading numpy-2.2.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.1 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.1/16.1 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "Successfully installed numpy-2.2.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb969475-ade5-4d26-9362-9d75dfe7e028",
   "metadata": {},
   "source": [
    "# FOR ALL Emotions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11cc3b0-d33d-4aa0-b48d-48f678a5aa85",
   "metadata": {},
   "source": [
    "half emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8c914f-e341-4255-9d12-d3038311b060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Processed happiness_1.npy with 45018 samples.\n",
      "[OK] Processed happiness_2.npy with 45018 samples.\n",
      "[OK] Processed happiness_3.npy with 45030 samples.\n",
      "[OK] Processed happiness_4.npy with 45030 samples.\n",
      "[OK] Processed happiness_5.npy with 45031 samples.\n",
      "[OK] Processed happiness_6.npy with 45030 samples.\n",
      "[OK] Processed happiness_7.npy with 45031 samples.\n",
      "[OK] Processed happiness_8.npy with 45031 samples.\n",
      "[OK] Processed happiness_9.npy with 45030 samples.\n",
      "[OK] Processed happiness_10.npy with 45018 samples.\n",
      "[DONE] Saved: output_datasets/happiness_sharegpt.json with 450267 samples\n",
      "\n",
      "[OK] Processed sadness_1.npy with 45030 samples.\n",
      "[OK] Processed sadness_2.npy with 45031 samples.\n",
      "[OK] Processed sadness_3.npy with 45031 samples.\n",
      "[OK] Processed sadness_4.npy with 45031 samples.\n",
      "[OK] Processed sadness_5.npy with 45030 samples.\n",
      "[OK] Processed sadness_6.npy with 45031 samples.\n",
      "[OK] Processed sadness_7.npy with 45031 samples.\n",
      "[OK] Processed sadness_8.npy with 45018 samples.\n",
      "[OK] Processed sadness_9.npy with 45031 samples.\n",
      "[OK] Processed sadness_10.npy with 45018 samples.\n",
      "[DONE] Saved: output_datasets/sadness_sharegpt.json with 450282 samples\n",
      "\n",
      "[OK] Processed anger_1.npy with 45030 samples.\n",
      "[OK] Processed anger_2.npy with 45031 samples.\n",
      "[OK] Processed anger_3.npy with 45030 samples.\n",
      "[OK] Processed anger_4.npy with 45018 samples.\n",
      "[OK] Processed anger_5.npy with 45031 samples.\n",
      "[OK] Processed anger_6.npy with 45031 samples.\n",
      "[OK] Processed anger_7.npy with 45018 samples.\n",
      "[OK] Processed anger_8.npy with 45030 samples.\n",
      "[OK] Processed anger_9.npy with 45031 samples.\n",
      "[OK] Processed anger_10.npy with 45031 samples.\n",
      "[DONE] Saved: output_datasets/anger_sharegpt.json with 450281 samples\n",
      "\n",
      "[OK] Processed fear_1.npy with 45031 samples.\n",
      "[OK] Processed fear_2.npy with 45031 samples.\n",
      "[OK] Processed fear_3.npy with 45031 samples.\n",
      "[OK] Processed fear_4.npy with 45031 samples.\n",
      "[OK] Processed fear_5.npy with 45017 samples.\n",
      "[OK] Processed fear_6.npy with 45030 samples.\n",
      "[OK] Processed fear_7.npy with 45018 samples.\n",
      "[OK] Processed fear_8.npy with 45017 samples.\n",
      "[OK] Processed fear_9.npy with 45031 samples.\n",
      "[OK] Processed fear_10.npy with 45031 samples.\n",
      "[DONE] Saved: output_datasets/fear_sharegpt.json with 450268 samples\n",
      "\n",
      "[OK] Processed surprise_1.npy with 45030 samples.\n",
      "[OK] Processed surprise_2.npy with 45030 samples.\n",
      "[OK] Processed surprise_3.npy with 45027 samples.\n",
      "[OK] Processed surprise_4.npy with 45030 samples.\n",
      "[OK] Processed surprise_5.npy with 45031 samples.\n",
      "[OK] Processed surprise_6.npy with 45018 samples.\n",
      "[OK] Processed surprise_7.npy with 45018 samples.\n",
      "[OK] Processed surprise_8.npy with 45017 samples.\n",
      "[OK] Processed surprise_9.npy with 45030 samples.\n",
      "[OK] Processed surprise_10.npy with 45030 samples.\n",
      "[DONE] Saved: output_datasets/surprise_sharegpt.json with 450261 samples\n",
      "\n",
      "[OK] Processed disgust_1.npy with 45031 samples.\n",
      "[OK] Processed disgust_2.npy with 45031 samples.\n",
      "[OK] Processed disgust_3.npy with 45031 samples.\n",
      "[OK] Processed disgust_4.npy with 45030 samples.\n",
      "[OK] Processed disgust_5.npy with 45017 samples.\n",
      "[OK] Processed disgust_6.npy with 45031 samples.\n",
      "[OK] Processed disgust_7.npy with 45031 samples.\n",
      "[OK] Processed disgust_8.npy with 45018 samples.\n",
      "[OK] Processed disgust_9.npy with 45031 samples.\n",
      "[OK] Processed disgust_10.npy with 45018 samples.\n",
      "[DONE] Saved: output_datasets/disgust_sharegpt.json with 450269 samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "BASE_DIR = \"/home/saihan/New folder/data\" \n",
    "OUTPUT_DIR = \"output_datasets\"  \n",
    "EMOTIONS = {\n",
    "    \"happiness\": \"Happy\",\n",
    "    \"sadness\": \"Sad\",\n",
    "    \"anger\": \"Angry\",\n",
    "    \"fear\": \"Fearful\",\n",
    "    \"surprise\": \"Surprised\",\n",
    "    \"disgust\": \"Disgusted\"\n",
    "}\n",
    "FILE_INDEXES = [1, 2, 3, 4,5,6,7,8,9,10] \n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "for emotion_key, label in EMOTIONS.items():\n",
    "    emotion_dir = os.path.join(BASE_DIR, emotion_key)\n",
    "    sharegpt_data = []\n",
    "\n",
    "    for i in FILE_INDEXES:\n",
    "        file_name = f\"{emotion_key}_{i}.npy\"\n",
    "        file_path = os.path.join(emotion_dir, file_name)\n",
    "\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"[SKIP] File not found: {file_path}\")\n",
    "            continue\n",
    "\n",
    "        # Load feature vectors\n",
    "        features = np.load(file_path)\n",
    "\n",
    "        # Format into chat structure\n",
    "        for feature_vector in features:\n",
    "            feature_str = \", \".join([f\"Feature {j+1} = {val:.2E}\" for j, val in enumerate(feature_vector)])\n",
    "            sharegpt_data.append({\n",
    "                \"conversations\": [\n",
    "                    {\"from\": \"user\", \"value\": f\"EMG features: {feature_str}\"},\n",
    "                    {\"from\": \"assistant\", \"value\": f\"Emotion: {label}\"}\n",
    "                ]\n",
    "            })\n",
    "\n",
    "        print(f\"[OK] Processed {file_name} with {len(features)} samples.\")\n",
    "\n",
    "    # Save the JSON file\n",
    "    output_file = os.path.join(OUTPUT_DIR, f\"{emotion_key}_sharegpt.json\")\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(sharegpt_data, f, indent=4)\n",
    "\n",
    "    print(f\"[DONE] Saved: {output_file} with {len(sharegpt_data)} samples\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bb05fcb-38f2-4d07-a584-9cabc9d2448b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMOTIONS = [\"happiness\", \"sadness\", \"anger\", \"fear\", \"surprise\", \"disgust\"]\n",
    "JSON_PATHS = [f\"data/{e}/{e}_{i}.npy\" for e in EMOTIONS for i in [1,2,3,4,5,6,7,8,9,10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14247e4b-637d-434c-961f-73d77ef26334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "Unsloth: Failed to patch Gemma3ForConditionalGeneration.\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
      "Loading model and tokenizer...\n",
      "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3050 Laptop GPU. Num GPUs = 1. Max memory: 4.0 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.1.\n",
      "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n",
      "Unsloth 2025.3.19 patched 28 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached sampled dataset...\n",
      "Train samples: 43200, Test samples: 4800\n",
      "Using batch size: 1, gradient accumulation: 8\n",
      "Max sequence length: 512\n",
      "Steps per epoch: 5400, Total steps: 5400\n",
      "Creating text field for dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7a25f4c7ded4c83b75e48b6e2b88e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/43200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4404ff5a9ed44beea8b125276f270f7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text field:\n",
      "### User:\n",
      "EMG features: Feature 1 = 5.37E-07, Feature 2 = -1.25E-05, Feature 3 = -6.49E-06, Feature 4 = -4.59E-06, Feature 5 = -5.71E-06, Feature 6 = -9.08E-06, Feature 7 = 1.07E-06, Feature 8 = 4.35E...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8864fb2bdb3844e683aa4e15a203dbaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"]:   0%|          | 0/43200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e46a4e19c284aae81aa38e689466192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"]:   0%|          | 0/4800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MEMORY STATUS BEFORE TRAINING ===\n",
      "GPU Memory allocated: 2.26GB\n",
      "GPU Memory cached: 2.28GB\n",
      "Starting optimized training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 43,200 | Num Epochs = 1 | Total steps = 5,400\n",
      "O^O/ \\_/ \\    Batch size per device = 1 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (1 x 8 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 12,156,928/3,000,000,000 (0.41% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5400' max='5400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5400/5400 6:13:25, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.513600</td>\n",
       "      <td>0.511031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.506700</td>\n",
       "      <td>0.507574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Not an error, but LlamaForCausalLM does not accept `num_items_in_batch`.\n",
      "Using gradient accumulation will be very slightly less accurate.\n",
      "Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\n",
      "/home/saihan/miniconda3/lib/python3.12/site-packages/peft/utils/other.py:1110: UserWarning: Unable to fetch remote file due to the following error (ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: f8c4a7e5-e6f5-4927-90cb-9a17dfc5df1d)') - silently ignoring the lookup for the file config.json in unsloth/llama-3.2-3b-instruct-unsloth-bnb-4bit.\n",
      "  warnings.warn(\n",
      "/home/saihan/miniconda3/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in unsloth/llama-3.2-3b-instruct-unsloth-bnb-4bit - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed successfully!\n",
      "=== MEMORY STATUS AFTER TRAINING ===\n",
      "GPU Memory allocated: 2.34GB\n",
      "GPU Memory cached: 2.44GB\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel, get_chat_template\n",
    "from transformers import TrainingArguments, DataCollatorForLanguageModeling\n",
    "from trl import SFTTrainer\n",
    "from datasets import load_dataset, concatenate_datasets, load_from_disk\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "from functools import partial\n",
    "import gc\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "MODEL_NAME = \"unsloth/Llama-3.2-3B-Instruct\"\n",
    "JSON_PATHS = [\n",
    "    \"output_datasets/happiness_sharegpt.json\",\n",
    "    \"output_datasets/sadness_sharegpt.json\",\n",
    "    \"output_datasets/anger_sharegpt.json\",\n",
    "    \"output_datasets/fear_sharegpt.json\",\n",
    "    \"output_datasets/surprise_sharegpt.json\",\n",
    "    \"output_datasets/disgust_sharegpt.json\"\n",
    "]\n",
    "CACHE_PATH = \"dataset_cache_emg\"\n",
    "MODEL_SAVE_PATH = \"stage1_model_emg_6emotions\"\n",
    "\n",
    "# === OPTIMIZATION SETTINGS FOR 4GB GPU ===\n",
    "MAX_SAMPLES = 50000  # Drastically reduce dataset size\n",
    "SUBSET_EACH_EMOTION = 8000  # ~8k samples per emotion = ~48k total\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "print(\"Loading model and tokenizer...\")\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    max_seq_length=1024,  # Reduced from 2048 to save memory\n",
    "    load_in_4bit=True,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# More aggressive LoRA settings for 4GB GPU\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=8,  # Reduced from 16\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_alpha=8,  # Reduced from 16\n",
    "    lora_dropout=0.1,  # Added dropout\n",
    "    bias=\"none\",\n",
    "    use_gradient_checkpointing=\"unsloth\",\n",
    "    random_state=3407,\n",
    "    use_rslora=False,\n",
    "    loftq_config=None,\n",
    ")\n",
    "\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template=\"llama-3\",\n",
    "    mapping={\"role\": \"from\", \"content\": \"value\", \"user\": \"user\", \"assistant\": \"assistant\"}\n",
    ")\n",
    "\n",
    "# === OPTIMIZED DATASET LOADING ===\n",
    "def load_and_sample_datasets():\n",
    "    \"\"\"Load datasets and sample a subset for faster training\"\"\"\n",
    "    if os.path.exists(CACHE_PATH + \"_sampled\"):\n",
    "        print(\"Loading cached sampled dataset...\")\n",
    "        return load_from_disk(CACHE_PATH + \"_sampled\")\n",
    "\n",
    "    datasets = []\n",
    "    for path in JSON_PATHS:\n",
    "        if os.path.exists(path):\n",
    "            print(f\"Loading and sampling {path}...\")\n",
    "            ds = load_dataset(\"json\", data_files=path, split=\"train\")\n",
    "            \n",
    "            # Sample a subset from each emotion dataset\n",
    "            if len(ds) > SUBSET_EACH_EMOTION:\n",
    "                ds = ds.shuffle(seed=42).select(range(SUBSET_EACH_EMOTION))\n",
    "                print(f\"Sampled {len(ds)} examples from {path}\")\n",
    "            \n",
    "            datasets.append(ds)\n",
    "        else:\n",
    "            print(f\"File not found: {path}\")\n",
    "\n",
    "    if not datasets:\n",
    "        raise FileNotFoundError(\"No valid dataset files found.\")\n",
    "\n",
    "    full_dataset = concatenate_datasets(datasets)\n",
    "    full_dataset = full_dataset.shuffle(seed=42)\n",
    "    \n",
    "    # Final cap on total samples\n",
    "    if len(full_dataset) > MAX_SAMPLES:\n",
    "        full_dataset = full_dataset.select(range(MAX_SAMPLES))\n",
    "    \n",
    "    print(f\"Final dataset size: {len(full_dataset)} samples\")\n",
    "    full_dataset.save_to_disk(CACHE_PATH + \"_sampled\")\n",
    "    return full_dataset\n",
    "\n",
    "# === 1. Load Sampled Dataset ===\n",
    "full_dataset = load_and_sample_datasets()\n",
    "\n",
    "# === 2. Train-Test Split ===\n",
    "split_data = full_dataset.train_test_split(test_size=0.1, seed=42)  # Reduced test size\n",
    "print(f\"Train samples: {len(split_data['train'])}, Test samples: {len(split_data['test'])}\")\n",
    "\n",
    "# === 3. Optimized Training Config for 4GB GPU ===\n",
    "total_samples = len(split_data[\"train\"])\n",
    "\n",
    "# Very conservative settings for 4GB GPU\n",
    "batch_size = 1  # Start with batch size of 1\n",
    "grad_accum = 8  # High gradient accumulation to simulate larger batches\n",
    "max_seq_length = 512  # Further reduced sequence length\n",
    "\n",
    "print(f\"Using batch size: {batch_size}, gradient accumulation: {grad_accum}\")\n",
    "print(f\"Max sequence length: {max_seq_length}\")\n",
    "\n",
    "num_epochs = 1  # Reduced epochs for faster training\n",
    "steps_per_epoch = max(1, total_samples // (batch_size * grad_accum))\n",
    "total_steps = steps_per_epoch * num_epochs\n",
    "warmup_steps = max(1, int(0.05 * total_steps))  # Reduced warmup\n",
    "\n",
    "print(f\"Steps per epoch: {steps_per_epoch}, Total steps: {total_steps}\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"training_outputs\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=grad_accum,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=max(100, steps_per_epoch // 2), \n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=max(200, steps_per_epoch // 2),  \n",
    "    num_train_epochs=num_epochs,\n",
    "    max_steps=total_steps,\n",
    "    learning_rate=2e-4, \n",
    "    weight_decay=0.01,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_steps=warmup_steps,\n",
    "    fp16=False,  # Force FP16 for memory savings\n",
    "    bf16=True,\n",
    "    dataloader_pin_memory=False,  \n",
    "    gradient_checkpointing=True,\n",
    "    dataloader_num_workers=0,  \n",
    "    remove_unused_columns=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\",\n",
    "    seed=42,\n",
    "    dataloader_drop_last=True,\n",
    "    prediction_loss_only=True,\n",
    "    save_total_limit=1,  \n",
    "    load_best_model_at_end=False,  \n",
    ")\n",
    "\n",
    "# === 4. Data Collator ===\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,\n",
    "    pad_to_multiple_of=8,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# === 5. Create text field for dataset ===\n",
    "def create_text_field(example):\n",
    "    \"\"\"Convert conversations to a single text field\"\"\"\n",
    "    conversations = example[\"conversations\"]\n",
    "    text = \"\"\n",
    "    \n",
    "    for turn in conversations:\n",
    "        role = turn.get(\"from\", \"\")\n",
    "        content = turn.get(\"value\", \"\")\n",
    "        \n",
    "        if role == \"user\":\n",
    "            text += f\"### User:\\n{content}\\n\"\n",
    "        elif role == \"assistant\":\n",
    "            text += f\"### Assistant:\\n{content}\\n\"\n",
    "    \n",
    "    return {\"text\": text}\n",
    "\n",
    "# Apply the text field creation to the dataset\n",
    "print(\"Creating text field for dataset...\")\n",
    "split_data[\"train\"] = split_data[\"train\"].map(create_text_field, num_proc=1)  # Reduced processes\n",
    "split_data[\"test\"] = split_data[\"test\"].map(create_text_field, num_proc=1)\n",
    "\n",
    "print(\"Sample text field:\")\n",
    "print(split_data[\"train\"][0][\"text\"][:200] + \"...\")\n",
    "\n",
    "# === 6. Trainer Initialization ===\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=split_data[\"train\"],\n",
    "    eval_dataset=split_data[\"test\"],\n",
    "    max_seq_length=max_seq_length,\n",
    "    data_collator=data_collator,\n",
    "    packing=False,\n",
    "    dataset_num_proc=1,\n",
    "    dataset_text_field=\"text\"\n",
    ")\n",
    "\n",
    "# === 7. Aggressive Memory Optimizations ===\n",
    "model.config.use_cache = False\n",
    "if hasattr(model, 'gradient_checkpointing_enable'):\n",
    "    model.gradient_checkpointing_enable()\n",
    "\n",
    "# Clear cache before training\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# === 8. Optimized Training Function ===\n",
    "def train_with_optimizations():\n",
    "    try:\n",
    "        print(\"=== MEMORY STATUS BEFORE TRAINING ===\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"GPU Memory allocated: {torch.cuda.memory_allocated()/1024**3:.2f}GB\")\n",
    "            print(f\"GPU Memory cached: {torch.cuda.memory_reserved()/1024**3:.2f}GB\")\n",
    "        \n",
    "        print(\"Starting optimized training...\")\n",
    "        trainer.train()\n",
    "\n",
    "        print(\"Training completed successfully!\")\n",
    "        trainer.save_model(MODEL_SAVE_PATH)\n",
    "        tokenizer.save_pretrained(MODEL_SAVE_PATH)\n",
    "        \n",
    "        print(\"=== MEMORY STATUS AFTER TRAINING ===\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"GPU Memory allocated: {torch.cuda.memory_allocated()/1024**3:.2f}GB\")\n",
    "            print(f\"GPU Memory cached: {torch.cuda.memory_reserved()/1024**3:.2f}GB\")\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        if \"out of memory\" in str(e).lower():\n",
    "            print(\"=== OUT OF MEMORY ERROR ===\")\n",
    "            print(\"Try these solutions:\")\n",
    "            print(\"1. Reduce batch_size to 1\")\n",
    "            print(\"2. Increase grad_accum to 16\")\n",
    "            print(\"3. Reduce max_seq_length to 256\")\n",
    "            print(\"4. Reduce r in LoRA to 4\")\n",
    "            print(\"5. Use even fewer samples (MAX_SAMPLES = 10000)\")\n",
    "        trainer.save_model(\"failed_training_checkpoint\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"Training failed: {str(e)}\")\n",
    "        trainer.save_model(\"failed_training_checkpoint\")\n",
    "        raise\n",
    "\n",
    "# Start training\n",
    "train_with_optimizations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d29c5f-5d9e-4973-ad87-4e96b3fc27a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78796c2-aca0-4e8f-9827-ca0343e4a902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e82dbf0-8ac7-4012-819e-22ae015e37a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/saihan/New folder/stage1_model_emg_6emotions\"\n",
    "metadata_path = \"/home/saihan/New folder/stage1_model_emg_6emotions/metadata.pkl\"\n",
    "dataset_path = \"/home/saihan/New folder/dataset_cache_emg_sampled\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1f7328-3345-4c05-a272-8ea8d6874d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "Unsloth: Failed to patch Gemma3ForConditionalGeneration.\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
      "Loading model and tokenizer...\n",
      "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3050 Laptop GPU. Num GPUs = 1. Max memory: 4.0 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.3.19 patched 28 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda, VRAM: 4.3 GB\n",
      "Loading test dataset...\n",
      "Test dataset size: 4800 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features and labels: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4800/4800 [00:00<00:00, 16861.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 4800 valid samples, skipped 0 invalid samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   0%|                                                                      | 1/1200 [00:02<45:06,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1:\n",
      "  Prompt: EMG features: Feature 1 = 1.11E-05, Feature 2 = 1.94E-05, Feature 3 = 1.15E-05, Feature 4 = 3.81E-06...\n",
      "  Response: emg features: feature 1 = 1.11e-05, feature 2 = 1.94e-05, feature 3 = 1.15e-05, feature 4 = 3.81e-06, feature 5 = 1.44e-05, feature 6 = 1.17e-05, feature 7 = 1.40e-05, feature 8 = 2.32e-05\n",
      "\n",
      "classify the emotion as one of: happy, sad, angry, fearful, surprised, disgusted. output only the emotion.\n",
      "\n",
      "fearful\n",
      "  Predicted: Happy\n",
      "Sample 2:\n",
      "  Prompt: EMG features: Feature 1 = -2.71E-05, Feature 2 = -2.65E-05, Feature 3 = 2.86E-05, Feature 4 = 2.06E-...\n",
      "  Response: emg features: feature 1 = -2.71e-05, feature 2 = -2.65e-05, feature 3 = 2.86e-05, feature 4 = 2.06e-05, feature 5 = 9.72e-06, feature 6 = 1.36e-05, feature 7 = -6.01e-06, feature 8 = -3.87e-05\n",
      "\n",
      "classify the emotion as one of: happy, sad, angry, fearful, surprised, disgusted. output only the emotion.\n",
      "\n",
      "fearful\n",
      "  Predicted: Happy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1200/1200 [18:44<00:00,  1.07it/s]\n",
      "/home/saihan/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/saihan/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/saihan/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.1669\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.17      1.00      0.29       801\n",
      "         Sad       0.00      0.00      0.00       813\n",
      "       Angry       0.00      0.00      0.00       787\n",
      "     Fearful       0.00      0.00      0.00       812\n",
      "   Surprised       0.00      0.00      0.00       839\n",
      "   Disgusted       0.00      0.00      0.00       748\n",
      "\n",
      "    accuracy                           0.17      4800\n",
      "   macro avg       0.03      0.17      0.05      4800\n",
      "weighted avg       0.03      0.17      0.05      4800\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from datasets import load_from_disk\n",
    "from unsloth import FastLanguageModel\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def evaluate_emg_model(model_path, dataset_path, emotions=[\"Happy\", \"Sad\", \"Angry\", \"Fearful\", \"Surprised\", \"Disgusted\"], batch_size=4, cache_dir=\"preprocessed_data\"):\n",
    "    # Initialize label mappings\n",
    "    label_map = {emotion: idx for idx, emotion in enumerate(emotions)}\n",
    "    id_to_label = {idx: emotion for emotion, idx in label_map.items()}\n",
    "    \n",
    "    # Load model and tokenizer\n",
    "    print(\"Loading model and tokenizer...\")\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_path,\n",
    "        max_seq_length=256,  # Reduced for speed\n",
    "        load_in_4bit=True,\n",
    "    )\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    print(f\"Using device: {device}, VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    \n",
    "    # Load test dataset\n",
    "    print(\"Loading test dataset...\")\n",
    "    dataset = load_from_disk(dataset_path)\n",
    "    test_dataset = dataset['test'] if 'test' in dataset else dataset.train_test_split(test_size=0.1, seed=42)['test']\n",
    "    print(f\"Test dataset size: {len(test_dataset)} samples\")\n",
    "    \n",
    "    # Cache preprocessed features and labels\n",
    "    cache_file = os.path.join(cache_dir, \"preprocessed.npz\")\n",
    "    if os.path.exists(cache_file):\n",
    "        print(\"Loading cached features and labels...\")\n",
    "        data = np.load(cache_file)\n",
    "        features, true_labels = data['features'], data['labels']\n",
    "    else:\n",
    "        def extract_features_and_labels(dataset):\n",
    "            features, true_labels = [], []\n",
    "            invalid_samples = 0\n",
    "            for i, example in enumerate(tqdm(dataset, desc=\"Extracting features and labels\")):\n",
    "                try:\n",
    "                    user_message = example[\"conversations\"][0][\"value\"]\n",
    "                    feature_values = [float(val) for val in re.findall(r\"Feature \\d+ = ([-\\d.E+]+)\", user_message)]\n",
    "                    if len(feature_values) != 8:\n",
    "                        invalid_samples += 1\n",
    "                        continue\n",
    "                    features.append(feature_values)\n",
    "                    \n",
    "                    label_text = example[\"conversations\"][1][\"value\"].replace(\"Emotion: \", \"\").strip()\n",
    "                    if label_text not in label_map:\n",
    "                        invalid_samples += 1\n",
    "                        continue\n",
    "                    true_labels.append(label_map[label_text])\n",
    "                except Exception as e:\n",
    "                    invalid_samples += 1\n",
    "                    print(f\"Error in sample {i}: {e}\")\n",
    "                    continue\n",
    "            print(f\"Extracted {len(features)} valid samples, skipped {invalid_samples} invalid samples\")\n",
    "            if len(features) == 0:\n",
    "                raise ValueError(\"No valid samples extracted\")\n",
    "            return np.array(features), np.array(true_labels)\n",
    "        \n",
    "        features, true_labels = extract_features_and_labels(test_dataset)\n",
    "        os.makedirs(cache_dir, exist_ok=True)\n",
    "        np.savez(cache_file, features=features, labels=true_labels)\n",
    "    \n",
    "    # Make predictions\n",
    "    def predict_emotions(features):\n",
    "        predictions = []\n",
    "        for i in tqdm(range(0, len(features), batch_size), desc=\"Predicting\"):\n",
    "            batch_features = features[i:i+batch_size]\n",
    "            prompts = [f\"EMG features: {', '.join(f'Feature {j+1} = {val:.2E}' for j, val in enumerate(f))}\\n\\nClassify the emotion as one of: {', '.join(emotions)}. Output only the emotion name.\" for f in batch_features]\n",
    "            \n",
    "            inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=5,  # Reduced for speed\n",
    "                    temperature=0.1,\n",
    "                    pad_token_id=tokenizer.eos_token_id\n",
    "                )\n",
    "            \n",
    "            for j, (output, prompt) in enumerate(zip(outputs, prompts)):\n",
    "                response =tokenizer.decode(output, skip_special_tokens=True).replace(prompt, \"\").strip().lower()\n",
    "                for emotion in emotions:\n",
    "                    if emotion.lower() in response:\n",
    "                        predictions.append(label_map[emotion])\n",
    "                        break\n",
    "                else:\n",
    "                    predictions.append(0)  # Default to Happy\n",
    "                    print(f\"‚ö†Ô∏è No emotion matched in response: '{response}'\")\n",
    "                if i == 0 and j < 2:  # Debug first two samples\n",
    "                    print(f\"Sample {i+j+1}:\")\n",
    "                    print(f\"  Prompt: {prompts[j][:100]}...\")\n",
    "                    print(f\"  Response: {response}\")\n",
    "                    print(f\"  Predicted: {id_to_label[predictions[-1]]}\")\n",
    "        if not predictions:\n",
    "            raise ValueError(\"No predictions generated\")\n",
    "        return np.array(predictions)\n",
    "    \n",
    "    predictions = predict_emotions(features)\n",
    "    \n",
    "    if len(true_labels) != len(predictions):\n",
    "        raise ValueError(f\"Mismatch: {len(true_labels)} true labels, {len(predictions)} predictions\")\n",
    "    \n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(true_labels, predictions, target_names=emotions, labels=list(id_to_label.keys())))\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(true_labels, predictions, labels=list(id_to_label.keys()))\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=emotions, yticklabels=emotions)\n",
    "    plt.title('Confusion Matrix - EMG Emotion Classification')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return accuracy, cm\n",
    "\n",
    "model_path = \"/home/saihan/New folder/stage1_model_emg_6emotions\"\n",
    "dataset_path = \"/home/saihan/New folder/dataset_cache_emg_sampled\"\n",
    "accuracy, confusion_matrix = evaluate_emg_model(model_path, dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0380074-e5fa-44f4-92df-23a664f50afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
      "Loading model and tokenizer...\n",
      "==((====))==  Unsloth 2025.6.5: Fast Llama patching. Transformers: 4.52.4.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3050 Laptop GPU. Num GPUs = 1. Max memory: 4.0 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.6.5 patched 28 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda, VRAM: 4.3 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "model_path = \"/home/saihan/New folder/stage1_model_emg_6emotions\"\n",
    "\n",
    "print(\"Loading model and tokenizer...\")\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_path,\n",
    "    max_seq_length=128, \n",
    "    load_in_4bit=True,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(f\"Using device: {device}, VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ef4016-4d74-4484-9b83-f2781904b5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: EMG features: Feature 1 = 3.96E-06, Feature 2 = 1.67E-05, Feature 3 = 1.81E-05, Feature 4 = 1.96E-05...\n",
      "Raw Response: emg features: feature 1 = 3.96e-06, feature 2 = 1.67e-05, feature 3 = 1.81e-05, feature 4 = 1.96e-05, feature 5 = 4.79e-06, feature 6 = 5.37e-07, feature 7 = 1.95e-07, feature 8 = -1.66e-06\n",
      "\n",
      "classify the emotion as one of: happy, sad, angry, fearful, surprised, disgusted. output only the emotion.\n",
      "\n",
      "sad\n",
      "Predicted Emotion: Happy\n"
     ]
    }
   ],
   "source": [
    "# Define emotions\n",
    "emotions = [\"Happy\", \"Sad\", \"Angry\", \"Fearful\", \"Surprised\", \"Disgusted\"]\n",
    "\n",
    "features = [3.96E-06, 1.67E-05, 1.81E-05, 1.96E-05, 4.79E-06, 5.37E-07, 1.95E-07, -1.66E-06]\n",
    "\n",
    "prompt = f\"EMG features: {', '.join(f'Feature {j+1} = {val:.2E}' for j, val in enumerate(features))}\\n\\nClassify the emotion as one of: {', '.join(emotions)}. Output only the emotion name.\"\n",
    "inputs = tokenizer([prompt], return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n",
    "with torch.no_grad():\n",
    "    output = model.generate(**inputs, max_new_tokens=5, temperature=0.1, pad_token_id=tokenizer.eos_token_id)\n",
    "response = tokenizer.decode(output[0], skip_special_tokens=True).replace(prompt, \"\").strip().lower()\n",
    "def extract_emotion(response, emotions):\n",
    "    for emotion in emotions:\n",
    "        if emotion.lower() in response:\n",
    "            return emotion\n",
    "    print(f\"No emotion matched in response: '{response}'\")\n",
    "    return \"fy\"  # Default\n",
    "\n",
    "predicted_emotion = extract_emotion(response, emotions)\n",
    "print(f\"Prompt: {prompt[:100]}...\")\n",
    "print(f\"Raw Response: {response}\")\n",
    "print(f\"Predicted Emotion: {predicted_emotion}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffb00acf-93c1-4012-be3b-6983b6ac7aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "Unsloth: Failed to patch Gemma3ForConditionalGeneration.\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3050 Laptop GPU. Num GPUs = 1. Max memory: 4.0 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.3.19 patched 28 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMG features: Feature 1 = 1.23E-4, Feature 2 = -2.34E-4, Feature 3 = 3.45E-4, Feature 4 = 4.56E-4, Feature 5 = -5.67E-4, Feature 6 = 6.78E-4, Feature 7 = 7.89E-4, Feature 8 = -8.90E-4\n",
      "\n",
      "Classify the emotion as one of: Happy, Sad, Angry, Fearful, Surprised, Disgusted. Output only the emotion name. Angry \n",
      "Note: Feature 1-8 are\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "\n",
    "model_path = \"/home/saihan/New folder/stage1_model_emg_6emotions\"\n",
    "emotions=[\"Happy\", \"Sad\", \"Angry\", \"Fearful\", \"Surprised\", \"Disgusted\"]\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(model_path, max_seq_length=512, load_in_4bit=True)\n",
    "model.eval()\n",
    "prompt = f\"EMG features: Feature 1 = 1.23E-4, Feature 2 = -2.34E-4, Feature 3 = 3.45E-4, Feature 4 = 4.56E-4, Feature 5 = -5.67E-4, Feature 6 = 6.78E-4, Feature 7 = 7.89E-4, Feature 8 = -8.90E-4\\n\\nClassify the emotion as one of: {', '.join(emotions)}. Output only the emotion name.\"\n",
    "inputs = tokenizer([prompt], return_tensors=\"pt\").to(model.device)\n",
    "output = model.generate(**inputs, max_new_tokens=10)\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0b13318-e286-4e2e-acae-9e046f5036ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445b865a-6603-4caa-b92d-253f95656090",
   "metadata": {},
   "source": [
    "## FIND A BIGGGG MISTAKE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38070547-80ac-469b-91f1-cb0bcf9bae64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/saihan/New folder/data/happiness/happiness_1.npy: 45018 total, 44986 valid\n",
      "/home/saihan/New folder/data/happiness/happiness_2.npy: 45018 total, 44986 valid\n",
      "/home/saihan/New folder/data/happiness/happiness_3.npy: 45030 total, 44998 valid\n",
      "/home/saihan/New folder/data/happiness/happiness_4.npy: 45030 total, 44998 valid\n",
      "/home/saihan/New folder/data/happiness/happiness_5.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/happiness/happiness_6.npy: 45030 total, 44998 valid\n",
      "/home/saihan/New folder/data/happiness/happiness_7.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/happiness/happiness_8.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/happiness/happiness_9.npy: 45030 total, 44998 valid\n",
      "/home/saihan/New folder/data/happiness/happiness_10.npy: 45018 total, 44986 valid\n",
      "/home/saihan/New folder/data/sadness/sadness_1.npy: 45030 total, 44998 valid\n",
      "/home/saihan/New folder/data/sadness/sadness_2.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/sadness/sadness_3.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/sadness/sadness_4.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/sadness/sadness_5.npy: 45030 total, 44998 valid\n",
      "/home/saihan/New folder/data/sadness/sadness_6.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/sadness/sadness_7.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/sadness/sadness_8.npy: 45018 total, 44986 valid\n",
      "/home/saihan/New folder/data/sadness/sadness_9.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/sadness/sadness_10.npy: 45018 total, 44986 valid\n",
      "/home/saihan/New folder/data/anger/anger_1.npy: 45030 total, 44998 valid\n",
      "/home/saihan/New folder/data/anger/anger_2.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/anger/anger_3.npy: 45030 total, 44998 valid\n",
      "/home/saihan/New folder/data/anger/anger_4.npy: 45018 total, 44986 valid\n",
      "/home/saihan/New folder/data/anger/anger_5.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/anger/anger_6.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/anger/anger_7.npy: 45018 total, 44986 valid\n",
      "/home/saihan/New folder/data/anger/anger_8.npy: 45030 total, 44998 valid\n",
      "/home/saihan/New folder/data/anger/anger_9.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/anger/anger_10.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/fear/fear_1.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/fear/fear_2.npy: 45031 total, 45000 valid\n",
      "/home/saihan/New folder/data/fear/fear_3.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/fear/fear_4.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/fear/fear_5.npy: 45017 total, 44985 valid\n",
      "/home/saihan/New folder/data/fear/fear_6.npy: 45030 total, 44998 valid\n",
      "/home/saihan/New folder/data/fear/fear_7.npy: 45018 total, 44986 valid\n",
      "/home/saihan/New folder/data/fear/fear_8.npy: 45017 total, 44985 valid\n",
      "/home/saihan/New folder/data/fear/fear_9.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/fear/fear_10.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/surprise/surprise_1.npy: 45030 total, 44998 valid\n",
      "/home/saihan/New folder/data/surprise/surprise_2.npy: 45030 total, 44998 valid\n",
      "/home/saihan/New folder/data/surprise/surprise_3.npy: 45027 total, 44995 valid\n",
      "/home/saihan/New folder/data/surprise/surprise_4.npy: 45030 total, 44998 valid\n",
      "/home/saihan/New folder/data/surprise/surprise_5.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/surprise/surprise_6.npy: 45018 total, 44986 valid\n",
      "/home/saihan/New folder/data/surprise/surprise_7.npy: 45018 total, 44986 valid\n",
      "/home/saihan/New folder/data/surprise/surprise_8.npy: 45017 total, 44985 valid\n",
      "/home/saihan/New folder/data/surprise/surprise_9.npy: 45030 total, 44998 valid\n",
      "/home/saihan/New folder/data/surprise/surprise_10.npy: 45030 total, 44998 valid\n",
      "/home/saihan/New folder/data/disgust/disgust_1.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/disgust/disgust_2.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/disgust/disgust_3.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/disgust/disgust_4.npy: 45030 total, 44998 valid\n",
      "/home/saihan/New folder/data/disgust/disgust_5.npy: 45017 total, 44985 valid\n",
      "/home/saihan/New folder/data/disgust/disgust_6.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/disgust/disgust_7.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/disgust/disgust_8.npy: 45018 total, 44986 valid\n",
      "/home/saihan/New folder/data/disgust/disgust_9.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/disgust/disgust_10.npy: 45018 total, 44986 valid\n",
      "Filtered all_features shape: (2699709, 8)\n"
     ]
    }
   ],
   "source": [
    "all_features = []\n",
    "for emotion_key, label in EMOTIONS.items():\n",
    "    emotion_dir = os.path.join(BASE_DIR, emotion_key)\n",
    "    for i in FILE_INDEXES:\n",
    "        file_path = os.path.join(emotion_dir, f\"{emotion_key}_{i}.npy\")\n",
    "        if os.path.exists(file_path):\n",
    "            features = np.load(file_path)\n",
    "            # Filter out samples with -1000\n",
    "            valid_features = features[~np.any(np.abs(features) >= 1000, axis=1)]\n",
    "            print(f\"{file_path}: {len(features)} total, {len(valid_features)} valid\")\n",
    "            all_features.append(valid_features)\n",
    "all_features = np.vstack(all_features) if all_features else np.array([])\n",
    "print(\"Filtered all_features shape:\", all_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c42a4de2-908b-4a8b-a13c-2bf03d1fc49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler mean: [ 3.05337439e-08  4.84248124e-09 -3.70331063e-08 -2.56159504e-08\n",
      " -1.26670911e-08 -6.41377720e-09 -6.31111304e-08 -2.04205977e-07]\n",
      "Scaler std: [4.15177371e-05 4.11676510e-05 3.30143197e-05 3.08727406e-05\n",
      " 3.40905403e-05 3.53525363e-05 7.72764198e-05 8.61056472e-05]\n"
     ]
    }
   ],
   "source": [
    "import joblib \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(all_features)\n",
    "joblib.dump(scaler, os.path.join(OUTPUT_DIR, \"scaler.pkl\"))\n",
    "print(\"Scaler mean:\", scaler.mean_)\n",
    "print(\"Scaler std:\", scaler.scale_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371621ef-fe85-4345-9a51-68e83c080b43",
   "metadata": {},
   "source": [
    "### UPDATED VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5e6e645-fd9b-4025-b208-eb1ee573d032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/saihan/New folder/data/happiness/happiness_1.npy: 45018 total, 44986 valid\n",
      "/home/saihan/New folder/data/happiness/happiness_2.npy: 45018 total, 44986 valid\n",
      "/home/saihan/New folder/data/happiness/happiness_3.npy: 45030 total, 44998 valid\n",
      "/home/saihan/New folder/data/happiness/happiness_4.npy: 45030 total, 44998 valid\n",
      "/home/saihan/New folder/data/happiness/happiness_5.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/happiness/happiness_6.npy: 45030 total, 44998 valid\n",
      "/home/saihan/New folder/data/happiness/happiness_7.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/happiness/happiness_8.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/happiness/happiness_9.npy: 45030 total, 44998 valid\n",
      "/home/saihan/New folder/data/happiness/happiness_10.npy: 45018 total, 44986 valid\n",
      "/home/saihan/New folder/data/sadness/sadness_1.npy: 45030 total, 44998 valid\n",
      "/home/saihan/New folder/data/sadness/sadness_2.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/sadness/sadness_3.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/sadness/sadness_4.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/sadness/sadness_5.npy: 45030 total, 44998 valid\n",
      "/home/saihan/New folder/data/sadness/sadness_6.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/sadness/sadness_7.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/sadness/sadness_8.npy: 45018 total, 44986 valid\n",
      "/home/saihan/New folder/data/sadness/sadness_9.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/sadness/sadness_10.npy: 45018 total, 44986 valid\n",
      "/home/saihan/New folder/data/anger/anger_1.npy: 45030 total, 44998 valid\n",
      "/home/saihan/New folder/data/anger/anger_2.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/anger/anger_3.npy: 45030 total, 44998 valid\n",
      "/home/saihan/New folder/data/anger/anger_4.npy: 45018 total, 44986 valid\n",
      "/home/saihan/New folder/data/anger/anger_5.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/anger/anger_6.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/anger/anger_7.npy: 45018 total, 44986 valid\n",
      "/home/saihan/New folder/data/anger/anger_8.npy: 45030 total, 44998 valid\n",
      "/home/saihan/New folder/data/anger/anger_9.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/anger/anger_10.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/fear/fear_1.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/fear/fear_2.npy: 45031 total, 45000 valid\n",
      "/home/saihan/New folder/data/fear/fear_3.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/fear/fear_4.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/fear/fear_5.npy: 45017 total, 44985 valid\n",
      "/home/saihan/New folder/data/fear/fear_6.npy: 45030 total, 44998 valid\n",
      "/home/saihan/New folder/data/fear/fear_7.npy: 45018 total, 44986 valid\n",
      "/home/saihan/New folder/data/fear/fear_8.npy: 45017 total, 44985 valid\n",
      "/home/saihan/New folder/data/fear/fear_9.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/fear/fear_10.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/surprise/surprise_1.npy: 45030 total, 44998 valid\n",
      "/home/saihan/New folder/data/surprise/surprise_2.npy: 45030 total, 44998 valid\n",
      "/home/saihan/New folder/data/surprise/surprise_3.npy: 45027 total, 44995 valid\n",
      "/home/saihan/New folder/data/surprise/surprise_4.npy: 45030 total, 44998 valid\n",
      "/home/saihan/New folder/data/surprise/surprise_5.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/surprise/surprise_6.npy: 45018 total, 44986 valid\n",
      "/home/saihan/New folder/data/surprise/surprise_7.npy: 45018 total, 44986 valid\n",
      "/home/saihan/New folder/data/surprise/surprise_8.npy: 45017 total, 44985 valid\n",
      "/home/saihan/New folder/data/surprise/surprise_9.npy: 45030 total, 44998 valid\n",
      "/home/saihan/New folder/data/surprise/surprise_10.npy: 45030 total, 44998 valid\n",
      "/home/saihan/New folder/data/disgust/disgust_1.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/disgust/disgust_2.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/disgust/disgust_3.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/disgust/disgust_4.npy: 45030 total, 44998 valid\n",
      "/home/saihan/New folder/data/disgust/disgust_5.npy: 45017 total, 44985 valid\n",
      "/home/saihan/New folder/data/disgust/disgust_6.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/disgust/disgust_7.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/disgust/disgust_8.npy: 45018 total, 44986 valid\n",
      "/home/saihan/New folder/data/disgust/disgust_9.npy: 45031 total, 44999 valid\n",
      "/home/saihan/New folder/data/disgust/disgust_10.npy: 45018 total, 44986 valid\n",
      "Filtered all_features shape: (2699709, 8)\n",
      "Raw all_features sample: [[-6.2499998e-06  3.4179686e-07 -9.2773435e-06  2.5878905e-06\n",
      "   6.6406246e-06 -4.7851563e-06 -7.8124998e-07 -8.0566406e-06]\n",
      " [-6.7382812e-06  3.8574217e-06 -8.5937500e-06  2.6855469e-06\n",
      "   7.8124995e-06 -5.2246091e-06 -2.1972655e-06 -4.1992184e-06]\n",
      " [-1.9042968e-06  5.0781250e-06 -2.8808593e-06  5.6152344e-06\n",
      "   1.3574218e-05 -2.5390625e-06  2.3925782e-06  0.0000000e+00]\n",
      " [-1.2695313e-06  5.3222657e-06 -1.7089843e-06  5.4199218e-06\n",
      "   1.5576172e-05 -6.3476563e-07  7.5683593e-06 -6.7382812e-06]\n",
      " [-1.5136718e-06  6.3476559e-06 -2.2460938e-06  4.3945311e-06\n",
      "   1.1132812e-05  0.0000000e+00  7.5195312e-06 -4.4433591e-06]]\n",
      "Scaler mean: [ 3.05337439e-08  4.84248124e-09 -3.70331063e-08 -2.56159504e-08\n",
      " -1.26670911e-08 -6.41377720e-09 -6.31111304e-08 -2.04205977e-07]\n",
      "Scaler std: [4.15177371e-05 4.11676510e-05 3.30143197e-05 3.08727406e-05\n",
      " 3.40905403e-05 3.53525363e-05 7.72764198e-05 8.61056472e-05]\n",
      "Normalized features sample: [[-1.5127350e-01  8.1849303e-03 -2.7988797e-01  8.4654175e-02\n",
      "   1.9516534e-01 -1.3517396e-01 -9.2931176e-03 -9.1195345e-02]\n",
      " [-1.6303429e-01  9.3582682e-02 -2.5918201e-01  8.7817363e-02\n",
      "   2.2954071e-01 -1.4760455e-01 -2.7617147e-02 -4.6396635e-02]\n",
      " [-4.6602506e-02  1.2323468e-01 -8.6139172e-02  1.8271297e-01\n",
      "   3.9855295e-01 -7.1639806e-02  3.1777989e-02  2.3715748e-03]\n",
      " [-3.1313486e-02  1.2916508e-01 -5.0643209e-02  1.7638659e-01\n",
      "   4.5727757e-01 -1.7773883e-02  9.8755479e-02 -7.5884394e-02]\n",
      " [-3.7193876e-02  1.5407275e-01 -6.6912197e-02  1.4317313e-01\n",
      "   3.2693759e-01  1.8142340e-04  9.8123625e-02 -4.9231999e-02]]\n",
      "[OK] Processed happiness_1.npy with 44986 samples.\n",
      "[DONE] Saved: output_datasets/happiness_sharegpt.json with 44986 samples\n",
      "\n",
      "[OK] Processed happiness_2.npy with 44986 samples.\n",
      "[DONE] Saved: output_datasets/happiness_sharegpt.json with 44986 samples\n",
      "\n",
      "[OK] Processed happiness_3.npy with 44998 samples.\n",
      "[DONE] Saved: output_datasets/happiness_sharegpt.json with 44998 samples\n",
      "\n",
      "[OK] Processed happiness_4.npy with 44998 samples.\n",
      "[DONE] Saved: output_datasets/happiness_sharegpt.json with 44998 samples\n",
      "\n",
      "[OK] Processed happiness_5.npy with 44999 samples.\n",
      "[DONE] Saved: output_datasets/happiness_sharegpt.json with 44999 samples\n",
      "\n",
      "[OK] Processed happiness_6.npy with 44998 samples.\n",
      "[DONE] Saved: output_datasets/happiness_sharegpt.json with 44998 samples\n",
      "\n",
      "[OK] Processed happiness_7.npy with 44999 samples.\n",
      "[DONE] Saved: output_datasets/happiness_sharegpt.json with 44999 samples\n",
      "\n",
      "[OK] Processed happiness_8.npy with 44999 samples.\n",
      "[DONE] Saved: output_datasets/happiness_sharegpt.json with 44999 samples\n",
      "\n",
      "[OK] Processed happiness_9.npy with 44998 samples.\n",
      "[DONE] Saved: output_datasets/happiness_sharegpt.json with 44998 samples\n",
      "\n",
      "[OK] Processed happiness_10.npy with 44986 samples.\n",
      "[DONE] Saved: output_datasets/happiness_sharegpt.json with 44986 samples\n",
      "\n",
      "[OK] Processed sadness_1.npy with 44998 samples.\n",
      "[DONE] Saved: output_datasets/sadness_sharegpt.json with 44998 samples\n",
      "\n",
      "[OK] Processed sadness_2.npy with 44999 samples.\n",
      "[DONE] Saved: output_datasets/sadness_sharegpt.json with 44999 samples\n",
      "\n",
      "[OK] Processed sadness_3.npy with 44999 samples.\n",
      "[DONE] Saved: output_datasets/sadness_sharegpt.json with 44999 samples\n",
      "\n",
      "[OK] Processed sadness_4.npy with 44999 samples.\n",
      "[DONE] Saved: output_datasets/sadness_sharegpt.json with 44999 samples\n",
      "\n",
      "[OK] Processed sadness_5.npy with 44998 samples.\n",
      "[DONE] Saved: output_datasets/sadness_sharegpt.json with 44998 samples\n",
      "\n",
      "[OK] Processed sadness_6.npy with 44999 samples.\n",
      "[DONE] Saved: output_datasets/sadness_sharegpt.json with 44999 samples\n",
      "\n",
      "[OK] Processed sadness_7.npy with 44999 samples.\n",
      "[DONE] Saved: output_datasets/sadness_sharegpt.json with 44999 samples\n",
      "\n",
      "[OK] Processed sadness_8.npy with 44986 samples.\n",
      "[DONE] Saved: output_datasets/sadness_sharegpt.json with 44986 samples\n",
      "\n",
      "[OK] Processed sadness_9.npy with 44999 samples.\n",
      "[DONE] Saved: output_datasets/sadness_sharegpt.json with 44999 samples\n",
      "\n",
      "[OK] Processed sadness_10.npy with 44986 samples.\n",
      "[DONE] Saved: output_datasets/sadness_sharegpt.json with 44986 samples\n",
      "\n",
      "[OK] Processed anger_1.npy with 44998 samples.\n",
      "[DONE] Saved: output_datasets/anger_sharegpt.json with 44998 samples\n",
      "\n",
      "[OK] Processed anger_2.npy with 44999 samples.\n",
      "[DONE] Saved: output_datasets/anger_sharegpt.json with 44999 samples\n",
      "\n",
      "[OK] Processed anger_3.npy with 44998 samples.\n",
      "[DONE] Saved: output_datasets/anger_sharegpt.json with 44998 samples\n",
      "\n",
      "[OK] Processed anger_4.npy with 44986 samples.\n",
      "[DONE] Saved: output_datasets/anger_sharegpt.json with 44986 samples\n",
      "\n",
      "[OK] Processed anger_5.npy with 44999 samples.\n",
      "[DONE] Saved: output_datasets/anger_sharegpt.json with 44999 samples\n",
      "\n",
      "[OK] Processed anger_6.npy with 44999 samples.\n",
      "[DONE] Saved: output_datasets/anger_sharegpt.json with 44999 samples\n",
      "\n",
      "[OK] Processed anger_7.npy with 44986 samples.\n",
      "[DONE] Saved: output_datasets/anger_sharegpt.json with 44986 samples\n",
      "\n",
      "[OK] Processed anger_8.npy with 44998 samples.\n",
      "[DONE] Saved: output_datasets/anger_sharegpt.json with 44998 samples\n",
      "\n",
      "[OK] Processed anger_9.npy with 44999 samples.\n",
      "[DONE] Saved: output_datasets/anger_sharegpt.json with 44999 samples\n",
      "\n",
      "[OK] Processed anger_10.npy with 44999 samples.\n",
      "[DONE] Saved: output_datasets/anger_sharegpt.json with 44999 samples\n",
      "\n",
      "[OK] Processed fear_1.npy with 44999 samples.\n",
      "[DONE] Saved: output_datasets/fear_sharegpt.json with 44999 samples\n",
      "\n",
      "[OK] Processed fear_2.npy with 45000 samples.\n",
      "[DONE] Saved: output_datasets/fear_sharegpt.json with 45000 samples\n",
      "\n",
      "[OK] Processed fear_3.npy with 44999 samples.\n",
      "[DONE] Saved: output_datasets/fear_sharegpt.json with 44999 samples\n",
      "\n",
      "[OK] Processed fear_4.npy with 44999 samples.\n",
      "[DONE] Saved: output_datasets/fear_sharegpt.json with 44999 samples\n",
      "\n",
      "[OK] Processed fear_5.npy with 44985 samples.\n",
      "[DONE] Saved: output_datasets/fear_sharegpt.json with 44985 samples\n",
      "\n",
      "[OK] Processed fear_6.npy with 44998 samples.\n",
      "[DONE] Saved: output_datasets/fear_sharegpt.json with 44998 samples\n",
      "\n",
      "[OK] Processed fear_7.npy with 44986 samples.\n",
      "[DONE] Saved: output_datasets/fear_sharegpt.json with 44986 samples\n",
      "\n",
      "[OK] Processed fear_8.npy with 44985 samples.\n",
      "[DONE] Saved: output_datasets/fear_sharegpt.json with 44985 samples\n",
      "\n",
      "[OK] Processed fear_9.npy with 44999 samples.\n",
      "[DONE] Saved: output_datasets/fear_sharegpt.json with 44999 samples\n",
      "\n",
      "[OK] Processed fear_10.npy with 44999 samples.\n",
      "[DONE] Saved: output_datasets/fear_sharegpt.json with 44999 samples\n",
      "\n",
      "[OK] Processed surprise_1.npy with 44998 samples.\n",
      "[DONE] Saved: output_datasets/surprise_sharegpt.json with 44998 samples\n",
      "\n",
      "[OK] Processed surprise_2.npy with 44998 samples.\n",
      "[DONE] Saved: output_datasets/surprise_sharegpt.json with 44998 samples\n",
      "\n",
      "[OK] Processed surprise_3.npy with 44995 samples.\n",
      "[DONE] Saved: output_datasets/surprise_sharegpt.json with 44995 samples\n",
      "\n",
      "[OK] Processed surprise_4.npy with 44998 samples.\n",
      "[DONE] Saved: output_datasets/surprise_sharegpt.json with 44998 samples\n",
      "\n",
      "[OK] Processed surprise_5.npy with 44999 samples.\n",
      "[DONE] Saved: output_datasets/surprise_sharegpt.json with 44999 samples\n",
      "\n",
      "[OK] Processed surprise_6.npy with 44986 samples.\n",
      "[DONE] Saved: output_datasets/surprise_sharegpt.json with 44986 samples\n",
      "\n",
      "[OK] Processed surprise_7.npy with 44986 samples.\n",
      "[DONE] Saved: output_datasets/surprise_sharegpt.json with 44986 samples\n",
      "\n",
      "[OK] Processed surprise_8.npy with 44985 samples.\n",
      "[DONE] Saved: output_datasets/surprise_sharegpt.json with 44985 samples\n",
      "\n",
      "[OK] Processed surprise_9.npy with 44998 samples.\n",
      "[DONE] Saved: output_datasets/surprise_sharegpt.json with 44998 samples\n",
      "\n",
      "[OK] Processed surprise_10.npy with 44998 samples.\n",
      "[DONE] Saved: output_datasets/surprise_sharegpt.json with 44998 samples\n",
      "\n",
      "[OK] Processed disgust_1.npy with 44999 samples.\n",
      "[DONE] Saved: output_datasets/disgust_sharegpt.json with 44999 samples\n",
      "\n",
      "[OK] Processed disgust_2.npy with 44999 samples.\n",
      "[DONE] Saved: output_datasets/disgust_sharegpt.json with 44999 samples\n",
      "\n",
      "[OK] Processed disgust_3.npy with 44999 samples.\n",
      "[DONE] Saved: output_datasets/disgust_sharegpt.json with 44999 samples\n",
      "\n",
      "[OK] Processed disgust_4.npy with 44998 samples.\n",
      "[DONE] Saved: output_datasets/disgust_sharegpt.json with 44998 samples\n",
      "\n",
      "[OK] Processed disgust_5.npy with 44985 samples.\n",
      "[DONE] Saved: output_datasets/disgust_sharegpt.json with 44985 samples\n",
      "\n",
      "[OK] Processed disgust_6.npy with 44999 samples.\n",
      "[DONE] Saved: output_datasets/disgust_sharegpt.json with 44999 samples\n",
      "\n",
      "[OK] Processed disgust_7.npy with 44999 samples.\n",
      "[DONE] Saved: output_datasets/disgust_sharegpt.json with 44999 samples\n",
      "\n",
      "[OK] Processed disgust_8.npy with 44986 samples.\n",
      "[DONE] Saved: output_datasets/disgust_sharegpt.json with 44986 samples\n",
      "\n",
      "[OK] Processed disgust_9.npy with 44999 samples.\n",
      "[DONE] Saved: output_datasets/disgust_sharegpt.json with 44999 samples\n",
      "\n",
      "[OK] Processed disgust_10.npy with 44986 samples.\n",
      "[DONE] Saved: output_datasets/disgust_sharegpt.json with 44986 samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "# === Settings ===\n",
    "BASE_DIR = \"/home/saihan/New folder/data\"\n",
    "OUTPUT_DIR = \"output_datasets\"\n",
    "EMOTIONS = {\n",
    "    \"happiness\": \"Happy\",\n",
    "    \"sadness\": \"Sad\",\n",
    "    \"anger\": \"Angry\",\n",
    "    \"fear\": \"Fearful\",\n",
    "    \"surprise\": \"Surprised\",\n",
    "    \"disgust\": \"Disgusted\"\n",
    "}\n",
    "FILE_INDEXES = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "OUTLIER_THRESHOLD = 1000\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Collect valid features\n",
    "all_features = []\n",
    "emotion_files = []\n",
    "for emotion_key, label in EMOTIONS.items():\n",
    "    emotion_dir = os.path.join(BASE_DIR, emotion_key)\n",
    "    for i in FILE_INDEXES:\n",
    "        file_name = f\"{emotion_key}_{i}.npy\"\n",
    "        file_path = os.path.join(emotion_dir, file_name)\n",
    "        if os.path.exists(file_path):\n",
    "            features = np.load(file_path)\n",
    "            valid_features = features[~np.any(np.abs(features) >= OUTLIER_THRESHOLD, axis=1)]\n",
    "            print(f\"{file_path}: {len(features)} total, {len(valid_features)} valid\")\n",
    "            all_features.append(valid_features)\n",
    "            emotion_files.append((emotion_key, label, file_name))\n",
    "        else:\n",
    "            print(f\"[SKIP] File not found: {file_path}\")\n",
    "\n",
    "all_features = np.vstack(all_features) if all_features else np.array([])\n",
    "print(\"Filtered all_features shape:\", all_features.shape)\n",
    "print(\"Raw all_features sample:\", all_features[:5])\n",
    "\n",
    "# Normalize\n",
    "if all_features.size > 0:\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(all_features)\n",
    "    joblib.dump(scaler, os.path.join(OUTPUT_DIR, \"scaler.pkl\"))\n",
    "    print(\"Scaler mean:\", scaler.mean_)\n",
    "    print(\"Scaler std:\", scaler.scale_)\n",
    "    print(\"Normalized features sample:\", scaler.transform(all_features[:5]))\n",
    "else:\n",
    "    scaler = None\n",
    "    print(\"[WARNING] No valid features found.\")\n",
    "\n",
    "# Convert to JSON\n",
    "for emotion_key, label, file_name in emotion_files:\n",
    "    file_path = os.path.join(BASE_DIR, emotion_key, file_name)\n",
    "    features = np.load(file_path)\n",
    "    valid_features = features[~np.any(np.abs(features) >= OUTLIER_THRESHOLD, axis=1)]\n",
    "    if scaler:\n",
    "        features = scaler.transform(valid_features)\n",
    "    else:\n",
    "        features = valid_features\n",
    "\n",
    "    sharegpt_data = []\n",
    "    for idx, feature_vector in enumerate(features):\n",
    "        feature_str = \", \".join([f\"Feature {j+1} = {val:.6E}\" for j, val in enumerate(feature_vector)])\n",
    "        sharegpt_data.append({\n",
    "            \"conversations\": [\n",
    "                {\"from\": \"user\", \"value\": f\"EMG features: {feature_str}\"},\n",
    "                {\"from\": \"assistant\", \"value\": f\"Emotion: {label}\"}\n",
    "            ],\n",
    "            \"raw_features\": feature_vector.tolist(),\n",
    "            \"metadata\": {\"file\": file_name, \"sample_index\": idx}\n",
    "        })\n",
    "\n",
    "    print(f\"[OK] Processed {file_name} with {len(features)} samples.\")\n",
    "    output_file = os.path.join(OUTPUT_DIR, f\"{emotion_key}_sharegpt.json\")\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(sharegpt_data, f, indent=4)\n",
    "    print(f\"[DONE] Saved: {output_file} with {len(sharegpt_data)} samples\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2de6127-cbf3-4626-a38d-17a99d8c28b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
      "Loading model and tokenizer...\n",
      "==((====))==  Unsloth 2025.6.5: Fast Llama patching. Transformers: 4.52.4.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3050 Laptop GPU. Num GPUs = 1. Max memory: 4.0 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.1.\n",
      "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n",
      "Unsloth 2025.6.5 patched 16 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and sampling output_datasets/happiness_sharegpt.json...\n",
      "Sampled 4000 examples from output_datasets/happiness_sharegpt.json\n",
      "Loading and sampling output_datasets/sadness_sharegpt.json...\n",
      "Sampled 4000 examples from output_datasets/sadness_sharegpt.json\n",
      "Loading and sampling output_datasets/anger_sharegpt.json...\n",
      "Sampled 4000 examples from output_datasets/anger_sharegpt.json\n",
      "Loading and sampling output_datasets/fear_sharegpt.json...\n",
      "Sampled 4000 examples from output_datasets/fear_sharegpt.json\n",
      "Loading and sampling output_datasets/surprise_sharegpt.json...\n",
      "Sampled 4000 examples from output_datasets/surprise_sharegpt.json\n",
      "Loading and sampling output_datasets/disgust_sharegpt.json...\n",
      "Sampled 4000 examples from output_datasets/disgust_sharegpt.json\n",
      "Final dataset size: 24000 samples\n",
      "Label distribution: conversations\n",
      "Emotion: Surprised    4000\n",
      "Emotion: Sad          4000\n",
      "Emotion: Happy        4000\n",
      "Emotion: Fearful      4000\n",
      "Emotion: Angry        4000\n",
      "Emotion: Disgusted    4000\n",
      "Name: count, dtype: int64\n",
      "Unique feature strings: 24000 out of 24000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "464fda08f4a54e048f1670b089471ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/24000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 21600, Test samples: 2400\n",
      "Creating text field for dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e78316cc15d04567834541e36535a9bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/21600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f7585ddc3d40be993edf3bc4dc736d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text field: ### User:\n",
      "EMG features: Feature 1 = 1.862611E-01, Feature 2 = -1.697271E-01, Feature 3 = -2.828459E-01, Feature 4 = -3.075810E-01, Feature 5 = -2.493042E-03, Feature 6 = -2.000893E-01, Feature 7 = 1.0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3af95296d6940bb98613976b66ab4ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"]:   0%|          | 0/21600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92279478bd0b48b9aaf54e9be4a2693a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"]:   0%|          | 0/2400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MEMORY STATUS BEFORE TRAINING ===\n",
      "GPU Memory allocated: 1.06GB\n",
      "GPU Memory cached: 1.07GB\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 21,600 | Num Epochs = 2 | Total steps = 5,400\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 5,636,096/1,000,000,000 (0.56% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1351' max='5400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1351/5400 1:02:33 < 3:07:45, 0.36 it/s, Epoch 0.50/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='1200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  48/1200 12:44 < 5:12:10, 0.06 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Not an error, but LlamaForCausalLM does not accept `num_items_in_batch`.\n",
      "Using gradient accumulation will be very slightly less accurate.\n",
      "Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel, get_chat_template\n",
    "from transformers import TrainingArguments, DataCollatorForLanguageModeling\n",
    "from trl import SFTTrainer\n",
    "from datasets import load_dataset, concatenate_datasets, load_from_disk\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import gc\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "MODEL_NAME = \"unsloth/Llama-3.2-1B-Instruct\"  # Smaller model for 4GB GPU\n",
    "JSON_PATHS = [\n",
    "    \"output_datasets/happiness_sharegpt.json\",\n",
    "    \"output_datasets/sadness_sharegpt.json\",\n",
    "    \"output_datasets/anger_sharegpt.json\",\n",
    "    \"output_datasets/fear_sharegpt.json\",\n",
    "    \"output_datasets/surprise_sharegpt.json\",\n",
    "    \"output_datasets/disgust_sharegpt.json\"\n",
    "]\n",
    "CACHE_PATH = \"dataset_cache_emgv2\"\n",
    "MODEL_SAVE_PATH = \"stage1_model_emg_6emotionsv2\"\n",
    "SUBSET_EACH_EMOTION = 4000  # 4k per emotion\n",
    "MAX_SAMPLES = 24000  # 6 √ó 4k\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# === LOAD MODEL ===\n",
    "print(\"Loading model and tokenizer...\")\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    max_seq_length=256,  # Reduced for EMG feature strings\n",
    "    load_in_4bit=True,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=8,  # Reduced for memory efficiency\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_alpha=8,\n",
    "    lora_dropout=0.1,  # Added dropout for regularization\n",
    "    bias=\"none\",\n",
    "    use_gradient_checkpointing=\"unsloth\",\n",
    "    random_state=3407,\n",
    "    use_rslora=False,\n",
    "    loftq_config=None,\n",
    ")\n",
    "\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template=\"llama-3\",\n",
    "    mapping={\"role\": \"from\", \"content\": \"value\", \"user\": \"user\", \"assistant\": \"assistant\"}\n",
    ")\n",
    "\n",
    "# === LOAD AND SAMPLE DATASETS ===\n",
    "def load_and_sample_datasets():\n",
    "    if os.path.exists(CACHE_PATH + \"_sampled\"):\n",
    "        print(\"Loading cached sampled dataset...\")\n",
    "        return load_from_disk(CACHE_PATH + \"_sampled\")\n",
    "\n",
    "    datasets = []\n",
    "    for path in JSON_PATHS:\n",
    "        if os.path.exists(path):\n",
    "            print(f\"Loading and sampling {path}...\")\n",
    "            ds = load_dataset(\"json\", data_files=path, split=\"train\")\n",
    "            if len(ds) > SUBSET_EACH_EMOTION:\n",
    "                ds = ds.shuffle(seed=42).select(range(SUBSET_EACH_EMOTION))\n",
    "                print(f\"Sampled {len(ds)} examples from {path}\")\n",
    "            datasets.append(ds)\n",
    "        else:\n",
    "            print(f\"File not found: {path}\")\n",
    "\n",
    "    if not datasets:\n",
    "        raise FileNotFoundError(\"No valid dataset files found.\")\n",
    "\n",
    "    full_dataset = concatenate_datasets(datasets).shuffle(seed=42)\n",
    "    if len(full_dataset) > MAX_SAMPLES:\n",
    "        full_dataset = full_dataset.select(range(MAX_SAMPLES))\n",
    "    \n",
    "    print(f\"Final dataset size: {len(full_dataset)} samples\")\n",
    "    # Verify label distribution\n",
    "    label_counts = full_dataset.to_pandas()[\"conversations\"].apply(lambda x: x[1][\"value\"]).value_counts()\n",
    "    print(\"Label distribution:\", label_counts)\n",
    "    # Verify feature diversity\n",
    "    feature_strings = full_dataset.to_pandas()[\"conversations\"].apply(lambda x: x[0][\"value\"])\n",
    "    print(f\"Unique feature strings: {len(set(feature_strings))} out of {len(feature_strings)}\")\n",
    "    \n",
    "    full_dataset.save_to_disk(CACHE_PATH + \"_sampled\")\n",
    "    return full_dataset\n",
    "\n",
    "# === LOAD DATASET ===\n",
    "full_dataset = load_and_sample_datasets()\n",
    "\n",
    "# === TRAIN-TEST SPLIT ===\n",
    "split_data = full_dataset.train_test_split(test_size=0.1, seed=42)\n",
    "print(f\"Train samples: {len(split_data['train'])}, Test samples: {len(split_data['test'])}\")\n",
    "\n",
    "# === CREATE TEXT FIELD ===\n",
    "def create_text_field(example):\n",
    "    conversations = example[\"conversations\"]\n",
    "    text = \"\"\n",
    "    for turn in conversations:\n",
    "        role = turn.get(\"from\", \"\")\n",
    "        content = turn.get(\"value\", \"\")\n",
    "        if role == \"user\":\n",
    "            text += f\"### User:\\n{content}\\n\"\n",
    "        elif role == \"assistant\":\n",
    "            text += f\"### Assistant:\\n{content}\\n\"\n",
    "    return {\"text\": text}\n",
    "\n",
    "# Cache preprocessed dataset\n",
    "if not os.path.exists(CACHE_PATH + \"_preprocessed\"):\n",
    "    print(\"Creating text field for dataset...\")\n",
    "    split_data[\"train\"] = split_data[\"train\"].map(create_text_field, num_proc=1)\n",
    "    split_data[\"test\"] = split_data[\"test\"].map(create_text_field, num_proc=1)\n",
    "    split_data.save_to_disk(CACHE_PATH + \"_preprocessed\")\n",
    "else:\n",
    "    split_data = load_from_disk(CACHE_PATH + \"_preprocessed\")\n",
    "\n",
    "print(\"Sample text field:\", split_data[\"train\"][0][\"text\"][:200] + \"...\")\n",
    "\n",
    "# === TRAINING CONFIG ===\n",
    "batch_size = 2\n",
    "grad_accum = 4\n",
    "max_seq_length = 256\n",
    "total_samples = len(split_data[\"train\"])\n",
    "steps_per_epoch = max(1, total_samples // (batch_size * grad_accum))\n",
    "num_epochs = 2\n",
    "total_steps = steps_per_epoch * num_epochs\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"training_outputs\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=grad_accum,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=max(100, steps_per_epoch // 2),\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=max(200, steps_per_epoch // 2),\n",
    "    num_train_epochs=num_epochs,\n",
    "    learning_rate=1e-4,  # Lowered for stability\n",
    "    weight_decay=0.01,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_steps=max(1, int(0.1 * total_steps)),\n",
    "    fp16=False,\n",
    "    bf16=True,\n",
    "    dataloader_pin_memory=False,\n",
    "    gradient_checkpointing=True,\n",
    "    dataloader_num_workers=0,\n",
    "    remove_unused_columns=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\",\n",
    "    seed=42,\n",
    "    dataloader_drop_last=True,\n",
    "    save_total_limit=1,\n",
    ")\n",
    "\n",
    "# === CUSTOM EVALUATION ===\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predicted_labels = []\n",
    "    true_labels = []\n",
    "    for pred, label in zip(predictions, labels):\n",
    "        pred_text = tokenizer.decode(pred, skip_special_tokens=True)\n",
    "        label_text = tokenizer.decode(label, skip_special_tokens=True)\n",
    "        pred_emotion = pred_text.split(\"Emotion: \")[-1].strip() if \"Emotion: \" in pred_text else \"Unknown\"\n",
    "        true_emotion = label_text.split(\"Emotion: \")[-1].strip()\n",
    "        predicted_labels.append(pred_emotion)\n",
    "        true_labels.append(true_emotion)\n",
    "    return {\"accuracy\": accuracy_score(true_labels, predicted_labels)}\n",
    "\n",
    "# === DATA COLLATOR ===\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,\n",
    "    pad_to_multiple_of=8,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# === TRAINER ===\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=split_data[\"train\"],\n",
    "    eval_dataset=split_data[\"test\"],\n",
    "    max_seq_length=max_seq_length,\n",
    "    data_collator=data_collator,\n",
    "    packing=False,\n",
    "    dataset_num_proc=1,\n",
    "    dataset_text_field=\"text\",\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# === MEMORY OPTIMIZATIONS ===\n",
    "model.config.use_cache = False\n",
    "if hasattr(model, 'gradient_checkpointing_enable'):\n",
    "    model.gradient_checkpointing_enable()\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# === TRAINING FUNCTION ===\n",
    "def train_with_optimizations():\n",
    "    try:\n",
    "        print(\"=== MEMORY STATUS BEFORE TRAINING ===\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"GPU Memory allocated: {torch.cuda.memory_allocated()/1024**3:.2f}GB\")\n",
    "            print(f\"GPU Memory cached: {torch.cuda.memory_reserved()/1024**3:.2f}GB\")\n",
    "        \n",
    "        print(\"Starting training...\")\n",
    "        trainer.train()\n",
    "        trainer.save_model(MODEL_SAVE_PATH)\n",
    "        tokenizer.save_pretrained(MODEL_SAVE_PATH)\n",
    "        \n",
    "        print(\"=== MEMORY STATUS AFTER TRAINING ===\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"GPU Memory allocated: {torch.cuda.memory_allocated()/1024**3:.2f}GB\")\n",
    "            print(f\"GPU Memory cached: {torch.cuda.memory_reserved()/1024**3:.2f}GB\")\n",
    "    except RuntimeError as e:\n",
    "        if \"out of memory\" in str(e).lower():\n",
    "            print(\"=== OUT OF MEMORY ERROR ===\")\n",
    "            print(\"Try reducing batch_size, max_seq_length, or r further.\")\n",
    "        trainer.save_model(\"failed_training_checkpoint\")\n",
    "        raise\n",
    "\n",
    "train_with_optimizations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb930a2d-f756-4f81-8c31-1ba0278e0077",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 21:14:04,855 - INFO - Loading and sampling .npy files...\n",
      "2025-06-25 21:14:04,863 - INFO - Sampled 500 samples from /home/saihan/New folder/data/happiness/happiness_1.npy\n",
      "2025-06-25 21:14:04,869 - INFO - Sampled 500 samples from /home/saihan/New folder/data/happiness/happiness_2.npy\n",
      "2025-06-25 21:14:04,876 - INFO - Sampled 500 samples from /home/saihan/New folder/data/happiness/happiness_3.npy\n",
      "2025-06-25 21:14:04,881 - INFO - Sampled 500 samples from /home/saihan/New folder/data/happiness/happiness_4.npy\n",
      "2025-06-25 21:14:04,886 - INFO - Sampled 500 samples from /home/saihan/New folder/data/happiness/happiness_5.npy\n",
      "2025-06-25 21:14:04,892 - INFO - Sampled 500 samples from /home/saihan/New folder/data/happiness/happiness_6.npy\n",
      "2025-06-25 21:14:04,897 - INFO - Sampled 500 samples from /home/saihan/New folder/data/happiness/happiness_7.npy\n",
      "2025-06-25 21:14:04,903 - INFO - Sampled 500 samples from /home/saihan/New folder/data/happiness/happiness_8.npy\n",
      "2025-06-25 21:14:04,909 - INFO - Sampled 500 samples from /home/saihan/New folder/data/happiness/happiness_9.npy\n",
      "2025-06-25 21:14:04,914 - INFO - Sampled 500 samples from /home/saihan/New folder/data/happiness/happiness_10.npy\n",
      "2025-06-25 21:14:04,920 - INFO - Sampled 500 samples from /home/saihan/New folder/data/sadness/sadness_1.npy\n",
      "2025-06-25 21:14:04,925 - INFO - Sampled 500 samples from /home/saihan/New folder/data/sadness/sadness_2.npy\n",
      "2025-06-25 21:14:04,931 - INFO - Sampled 500 samples from /home/saihan/New folder/data/sadness/sadness_3.npy\n",
      "2025-06-25 21:14:04,936 - INFO - Sampled 500 samples from /home/saihan/New folder/data/sadness/sadness_4.npy\n",
      "2025-06-25 21:14:04,942 - INFO - Sampled 500 samples from /home/saihan/New folder/data/sadness/sadness_5.npy\n",
      "2025-06-25 21:14:04,947 - INFO - Sampled 500 samples from /home/saihan/New folder/data/sadness/sadness_6.npy\n",
      "2025-06-25 21:14:04,953 - INFO - Sampled 500 samples from /home/saihan/New folder/data/sadness/sadness_7.npy\n",
      "2025-06-25 21:14:04,959 - INFO - Sampled 500 samples from /home/saihan/New folder/data/sadness/sadness_8.npy\n",
      "2025-06-25 21:14:04,964 - INFO - Sampled 500 samples from /home/saihan/New folder/data/sadness/sadness_9.npy\n",
      "2025-06-25 21:14:04,970 - INFO - Sampled 500 samples from /home/saihan/New folder/data/sadness/sadness_10.npy\n",
      "2025-06-25 21:14:04,975 - INFO - Sampled 500 samples from /home/saihan/New folder/data/anger/anger_1.npy\n",
      "2025-06-25 21:14:04,982 - INFO - Sampled 500 samples from /home/saihan/New folder/data/anger/anger_2.npy\n",
      "2025-06-25 21:14:04,987 - INFO - Sampled 500 samples from /home/saihan/New folder/data/anger/anger_3.npy\n",
      "2025-06-25 21:14:04,993 - INFO - Sampled 500 samples from /home/saihan/New folder/data/anger/anger_4.npy\n",
      "2025-06-25 21:14:05,000 - INFO - Sampled 500 samples from /home/saihan/New folder/data/anger/anger_5.npy\n",
      "2025-06-25 21:14:05,005 - INFO - Sampled 500 samples from /home/saihan/New folder/data/anger/anger_6.npy\n",
      "2025-06-25 21:14:05,011 - INFO - Sampled 500 samples from /home/saihan/New folder/data/anger/anger_7.npy\n",
      "2025-06-25 21:14:05,016 - INFO - Sampled 500 samples from /home/saihan/New folder/data/anger/anger_8.npy\n",
      "2025-06-25 21:14:05,021 - INFO - Sampled 500 samples from /home/saihan/New folder/data/anger/anger_9.npy\n",
      "2025-06-25 21:14:05,026 - INFO - Sampled 500 samples from /home/saihan/New folder/data/anger/anger_10.npy\n",
      "2025-06-25 21:14:05,031 - INFO - Sampled 500 samples from /home/saihan/New folder/data/fear/fear_1.npy\n",
      "2025-06-25 21:14:05,036 - INFO - Sampled 500 samples from /home/saihan/New folder/data/fear/fear_2.npy\n",
      "2025-06-25 21:14:05,041 - INFO - Sampled 500 samples from /home/saihan/New folder/data/fear/fear_3.npy\n",
      "2025-06-25 21:14:05,046 - INFO - Sampled 500 samples from /home/saihan/New folder/data/fear/fear_4.npy\n",
      "2025-06-25 21:14:05,054 - INFO - Sampled 500 samples from /home/saihan/New folder/data/fear/fear_5.npy\n",
      "2025-06-25 21:14:05,059 - INFO - Sampled 500 samples from /home/saihan/New folder/data/fear/fear_6.npy\n",
      "2025-06-25 21:14:05,065 - INFO - Sampled 500 samples from /home/saihan/New folder/data/fear/fear_7.npy\n",
      "2025-06-25 21:14:05,070 - INFO - Sampled 500 samples from /home/saihan/New folder/data/fear/fear_8.npy\n",
      "2025-06-25 21:14:05,077 - INFO - Sampled 500 samples from /home/saihan/New folder/data/fear/fear_9.npy\n",
      "2025-06-25 21:14:05,083 - INFO - Sampled 500 samples from /home/saihan/New folder/data/fear/fear_10.npy\n",
      "2025-06-25 21:14:05,087 - INFO - Sampled 500 samples from /home/saihan/New folder/data/surprise/surprise_1.npy\n",
      "2025-06-25 21:14:05,094 - INFO - Sampled 500 samples from /home/saihan/New folder/data/surprise/surprise_2.npy\n",
      "2025-06-25 21:14:05,100 - INFO - Sampled 500 samples from /home/saihan/New folder/data/surprise/surprise_3.npy\n",
      "2025-06-25 21:14:05,106 - INFO - Sampled 500 samples from /home/saihan/New folder/data/surprise/surprise_4.npy\n",
      "2025-06-25 21:14:05,112 - INFO - Sampled 500 samples from /home/saihan/New folder/data/surprise/surprise_5.npy\n",
      "2025-06-25 21:14:05,116 - INFO - Sampled 500 samples from /home/saihan/New folder/data/surprise/surprise_6.npy\n",
      "2025-06-25 21:14:05,122 - INFO - Sampled 500 samples from /home/saihan/New folder/data/surprise/surprise_7.npy\n",
      "2025-06-25 21:14:05,127 - INFO - Sampled 500 samples from /home/saihan/New folder/data/surprise/surprise_8.npy\n",
      "2025-06-25 21:14:05,133 - INFO - Sampled 500 samples from /home/saihan/New folder/data/surprise/surprise_9.npy\n",
      "2025-06-25 21:14:05,138 - INFO - Sampled 500 samples from /home/saihan/New folder/data/surprise/surprise_10.npy\n",
      "2025-06-25 21:14:05,144 - INFO - Sampled 500 samples from /home/saihan/New folder/data/disgust/disgust_1.npy\n",
      "2025-06-25 21:14:05,150 - INFO - Sampled 500 samples from /home/saihan/New folder/data/disgust/disgust_2.npy\n",
      "2025-06-25 21:14:05,155 - INFO - Sampled 500 samples from /home/saihan/New folder/data/disgust/disgust_3.npy\n",
      "2025-06-25 21:14:05,161 - INFO - Sampled 500 samples from /home/saihan/New folder/data/disgust/disgust_4.npy\n",
      "2025-06-25 21:14:05,166 - INFO - Sampled 500 samples from /home/saihan/New folder/data/disgust/disgust_5.npy\n",
      "2025-06-25 21:14:05,171 - INFO - Sampled 500 samples from /home/saihan/New folder/data/disgust/disgust_6.npy\n",
      "2025-06-25 21:14:05,176 - INFO - Sampled 500 samples from /home/saihan/New folder/data/disgust/disgust_7.npy\n",
      "2025-06-25 21:14:05,181 - INFO - Sampled 500 samples from /home/saihan/New folder/data/disgust/disgust_8.npy\n",
      "2025-06-25 21:14:05,186 - INFO - Sampled 500 samples from /home/saihan/New folder/data/disgust/disgust_9.npy\n",
      "2025-06-25 21:14:05,191 - INFO - Sampled 500 samples from /home/saihan/New folder/data/disgust/disgust_10.npy\n",
      "2025-06-25 21:14:05,194 - INFO - Valid data shape: (30000, 8)\n",
      "2025-06-25 21:14:05,195 - INFO - Total samples: 30000\n",
      "2025-06-25 21:14:05,201 - INFO - Class distribution: Counter({np.str_('Happy'): 5000, np.str_('Sad'): 5000, np.str_('Angry'): 5000, np.str_('Fearful'): 5000, np.str_('Surprised'): 5000, np.str_('Disgusted'): 5000})\n",
      "2025-06-25 21:14:05,202 - INFO - Preprocessing data...\n",
      "2025-06-25 21:14:05,209 - INFO - Scaler mean (first feature): 1.92e-07, std: 4.12e-05\n",
      "2025-06-25 21:14:05,214 - INFO - Train size: 27000, Test size: 3000\n",
      "2025-06-25 21:14:05,215 - INFO - Training SVM...\n",
      "2025-06-25 21:14:33,093 - INFO - SVM Accuracy: 0.3633\n",
      "2025-06-25 21:14:33,105 - INFO - \n",
      "Classification Report:\n",
      "2025-06-25 21:14:33,115 - INFO -               precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.35      0.14      0.20       535\n",
      "         Sad       0.53      0.27      0.36       481\n",
      "       Angry       0.26      0.26      0.26       482\n",
      "     Fearful       0.68      0.58      0.62       485\n",
      "   Surprised       0.27      0.73      0.40       510\n",
      "   Disgusted       0.40      0.21      0.28       507\n",
      "\n",
      "    accuracy                           0.36      3000\n",
      "   macro avg       0.42      0.36      0.35      3000\n",
      "weighted avg       0.41      0.36      0.35      3000\n",
      "\n",
      "2025-06-25 21:14:33,398 - INFO - Confusion matrix saved to /home/saihan/New folder/emg_project/svm_confusion_matrix_reduced.png\n",
      "2025-06-25 21:14:33,529 - INFO - F1-score plot saved to /home/saihan/New folder/emg_project/svm_f1_scores_reduced.png\n",
      "2025-06-25 21:14:33,536 - INFO - SVM model saved to /home/saihan/New folder/emg_project/svm_emg_model_reduced.pkl\n",
      "2025-06-25 21:14:33,552 - INFO - Results saved to /home/saihan/New folder/emg_project/svm_results_reduced.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.3633\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import logging\n",
    "import joblib\n",
    "from collections import Counter\n",
    "\n",
    "# === SETUP LOGGING ===\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "EMOTIONS = {\n",
    "    \"happiness\": \"Happy\",\n",
    "    \"sadness\": \"Sad\",\n",
    "    \"anger\": \"Angry\",\n",
    "    \"fear\": \"Fearful\",\n",
    "    \"surprise\": \"Surprised\",\n",
    "    \"disgust\": \"Disgusted\"\n",
    "}\n",
    "DATA_ROOT = \"/home/saihan/New folder/data\"\n",
    "OUTPUT_DIR = \"/home/saihan/New folder/emg_project\"\n",
    "SAMPLES_PER_FILE = 500  # ~500 samples per .npy file\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "RESULT_FILE = os.path.join(OUTPUT_DIR, \"svm_results_reduced.txt\")\n",
    "CM_PLOT_PATH = os.path.join(OUTPUT_DIR, \"svm_confusion_matrix_reduced.png\")\n",
    "F1_PLOT_PATH = os.path.join(OUTPUT_DIR, \"svm_f1_scores_reduced.png\")\n",
    "\n",
    "# === SVM EVALUATION FUNCTION ===\n",
    "def evaluate_svm_emg(data_root=DATA_ROOT, emotions=EMOTIONS, output_dir=OUTPUT_DIR, samples_per_file=SAMPLES_PER_FILE):\n",
    "    data, labels = [], []\n",
    "    invalid_files = []\n",
    "    valid_file_count = 0\n",
    "\n",
    "    # Load and sample .npy files\n",
    "    logger.info(\"Loading and sampling .npy files...\")\n",
    "    for emotion_key, label in emotions.items():\n",
    "        emotion_dir = os.path.join(data_root, emotion_key)\n",
    "        if not os.path.exists(emotion_dir):\n",
    "            logger.warning(f\"Directory not found: {emotion_dir}\")\n",
    "            for i in range(1, 11):\n",
    "                invalid_files.append(os.path.join(emotion_dir, f\"{emotion_key}_{i}.npy\"))\n",
    "            continue\n",
    "        for i in range(1, 11):\n",
    "            file_path = os.path.join(emotion_dir, f\"{emotion_key}_{i}.npy\")\n",
    "            if os.path.exists(file_path):\n",
    "                try:\n",
    "                    features = np.load(file_path)\n",
    "                    if features.size == 0:\n",
    "                        logger.warning(f\"Empty file: {file_path}\")\n",
    "                        invalid_files.append(file_path)\n",
    "                        continue\n",
    "                    if features.ndim != 2 or features.shape[1] != 8:\n",
    "                        logger.warning(f\"Invalid shape in {file_path}: {features.shape}, expected (n_samples, 8)\")\n",
    "                        invalid_files.append(file_path)\n",
    "                        continue\n",
    "                    # Filter outliers\n",
    "                    valid_features = features[~np.any(np.abs(features) >= 1000, axis=1)]\n",
    "                    if valid_features.shape[0] == 0:\n",
    "                        logger.warning(f\"No valid samples in {file_path} after outlier filtering\")\n",
    "                        invalid_files.append(file_path)\n",
    "                        continue\n",
    "                    # Sample up to samples_per_file\n",
    "                    sample_size = min(samples_per_file, valid_features.shape[0])\n",
    "                    indices = np.random.choice(valid_features.shape[0], sample_size, replace=False)\n",
    "                    sampled_features = valid_features[indices]\n",
    "                    data.append(sampled_features)\n",
    "                    labels.extend([label] * sample_size)\n",
    "                    valid_file_count += 1\n",
    "                    logger.info(f\"Sampled {sample_size} samples from {file_path}\")\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error loading {file_path}: {e}\")\n",
    "                    invalid_files.append(file_path)\n",
    "            else:\n",
    "                logger.warning(f\"File not found: {file_path}\")\n",
    "                invalid_files.append(file_path)\n",
    "\n",
    "    # Check if any valid data was loaded\n",
    "    if not data:\n",
    "        error_msg = f\"No valid samples loaded. Invalid files: {invalid_files}\"\n",
    "        logger.error(error_msg)\n",
    "        with open(RESULT_FILE, \"w\") as f:\n",
    "            f.write(error_msg + \"\\n\")\n",
    "        raise ValueError(error_msg)\n",
    "\n",
    "    # Combine data\n",
    "    data = np.vstack(data)\n",
    "    labels = np.array(labels)\n",
    "    logger.info(f\"Valid data shape: {data.shape}\")\n",
    "    logger.info(f\"Total samples: {len(labels)}\")\n",
    "    logger.info(f\"Class distribution: {Counter(labels)}\")\n",
    "\n",
    "    # Check for sufficient samples\n",
    "    if data.shape[0] < 2:\n",
    "        error_msg = f\"Insufficient samples ({data.shape[0]}) for training\"\n",
    "        logger.error(error_msg)\n",
    "        with open(RESULT_FILE, \"w\") as f:\n",
    "            f.write(error_msg + \"\\n\")\n",
    "        raise ValueError(error_msg)\n",
    "\n",
    "    # Preprocess data\n",
    "    logger.info(\"Preprocessing data...\")\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "    logger.info(f\"Scaler mean (first feature): {scaler.mean_[0]:.2e}, std: {np.sqrt(scaler.var_[0]):.2e}\")\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data_scaled, labels, test_size=0.1, random_state=42\n",
    "    )\n",
    "    logger.info(f\"Train size: {len(X_train)}, Test size: {len(X_test)}\")\n",
    "\n",
    "    # Train SVM\n",
    "    logger.info(\"Training SVM...\")\n",
    "    svm = SVC(kernel=\"rbf\", C=1.0, random_state=42)\n",
    "    svm.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate\n",
    "    predictions = svm.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    logger.info(f\"SVM Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Classification report\n",
    "    report = classification_report(y_test, predictions, target_names=list(emotions.values()), output_dict=True)\n",
    "    logger.info(\"\\nClassification Report:\")\n",
    "    logger.info(classification_report(y_test, predictions, target_names=list(emotions.values())))\n",
    "\n",
    "    # Confusion matrix plot\n",
    "    cm = confusion_matrix(y_test, predictions, labels=list(emotions.values()))\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=list(emotions.values()), yticklabels=list(emotions.values()))\n",
    "    plt.title('Confusion Matrix - SVM EMG Emotion Classification')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(CM_PLOT_PATH)\n",
    "    plt.close()\n",
    "    logger.info(f\"Confusion matrix saved to {CM_PLOT_PATH}\")\n",
    "\n",
    "    # F1-score bar plot\n",
    "    f1_scores = [report[emotion]['f1-score'] for emotion in emotions.values()]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=list(emotions.values()), y=f1_scores, hue=list(emotions.values()), palette='viridis', legend=False)\n",
    "    plt.title('F1-Scores per Emotion - SVM EMG Classification')\n",
    "    plt.xlabel('Emotion')\n",
    "    plt.ylabel('F1-Score')\n",
    "    plt.ylim(0, 1)\n",
    "    for i, f1 in enumerate(f1_scores):\n",
    "        plt.text(i, f1 + 0.02, f'{f1:.2f}', ha='center', va='bottom')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(F1_PLOT_PATH)\n",
    "    plt.close()\n",
    "    logger.info(f\"F1-score plot saved to {F1_PLOT_PATH}\")\n",
    "\n",
    "    # Save model\n",
    "    model_path = os.path.join(output_dir, \"svm_emg_model_reduced.pkl\")\n",
    "    joblib.dump(svm, model_path)\n",
    "    logger.info(f\"SVM model saved to {model_path}\")\n",
    "\n",
    "    # Save results\n",
    "    with open(RESULT_FILE, \"w\") as f:\n",
    "        f.write(f\"SVM Accuracy: {accuracy:.4f}\\n\\n\")\n",
    "        f.write(\"Classification Report:\\n\")\n",
    "        f.write(classification_report(y_test, predictions, target_names=list(emotions.values())))\n",
    "        f.write(f\"\\nValid files loaded: {valid_file_count}\\n\")\n",
    "        f.write(f\"Total samples: {len(labels)}\\n\")\n",
    "        f.write(f\"Class distribution: {Counter(labels)}\\n\")\n",
    "        if invalid_files:\n",
    "            f.write(\"Invalid or missing files:\\n\")\n",
    "            f.write(\"\\n\".join(invalid_files) + \"\\n\")\n",
    "    logger.info(f\"Results saved to {RESULT_FILE}\")\n",
    "\n",
    "    return accuracy, cm, f1_scores\n",
    "\n",
    "# === USAGE ===\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        accuracy, confusion_matrix, f1_scores = evaluate_svm_emg()\n",
    "        print(f\"SVM Accuracy: {accuracy:.4f}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe32423d-ffbd-48c7-a411-31ff1dc76761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jiwer\n",
      "  Downloading jiwer-4.0.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting click>=8.1.8 (from jiwer)\n",
      "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting rapidfuzz>=3.9.7 (from jiwer)\n",
      "  Downloading rapidfuzz-3.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Downloading jiwer-4.0.0-py3-none-any.whl (23 kB)\n",
      "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Downloading rapidfuzz-3.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz, click, jiwer\n",
      "Successfully installed click-8.2.1 jiwer-4.0.0 rapidfuzz-3.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3e79aa1-58bf-4da8-8f89-02076d4a8943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3eda89d-9a37-4d72-bbde-b46bf8a22267",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-28 09:58:54,684 - INFO - Loading tokenizer...\n",
      "2025-06-28 09:58:58,072 - INFO - Loading EMG sequences...\n",
      "2025-06-28 09:58:58,740 - INFO - Loaded data shape: (20000, 20, 8), Labels: 20000, Target texts: 20000\n",
      "2025-06-28 09:58:58,741 - INFO - Preparing dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc67805e7e64c11a7e875669946abd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-28 09:59:26,210 - INFO - Saving processed data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9f825563f154c40ba513d80f67eb15f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/16000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0557497090224612b5675207e20dc87b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-28 09:59:27,103 - INFO - Data processing complete! Saved to /home/saihan/New folder/emg_project/processed_data\n",
      "2025-06-28 09:59:27,107 - INFO - Train samples: 16000, Test samples: 4000\n"
     ]
    }
   ],
   "source": [
    "# data_preprocessing.py\n",
    "# Compatible with unsloth/Mistral-Small-3.2-24B-Instruct-2506-unsloth-bnb-4bit\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "import logging\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configuration\n",
    "DATA_ROOT = \"/home/saihan/New folder/data\"\n",
    "PROCESSED_DATA_DIR = \"/home/saihan/New folder/emg_project/processed_data\"\n",
    "SAMPLES_PER_FILE = 500\n",
    "SEQ_LEN = 20\n",
    "USE_SLIDING_WINDOW = True\n",
    "FILES_PER_EMOTION = 10\n",
    "\n",
    "EMOTIONS = {\n",
    "    0: \"Happy\",\n",
    "    1: \"Sad\",\n",
    "    2: \"Angry\",\n",
    "    3: \"Neutral\"\n",
    "}\n",
    "EMOTION_TO_DIR = {\n",
    "    \"Happy\": \"happiness\",\n",
    "    \"Sad\": \"sadness\",\n",
    "    \"Angry\": \"anger\",\n",
    "    \"Neutral\": \"neutral\"\n",
    "}\n",
    "\n",
    "def load_emg_sequences(data_root, emotions, samples_per_file, seq_len):\n",
    "    logger.info(\"Loading EMG sequences...\")\n",
    "    data, labels, target_texts, invalid_files = [], [], [], []\n",
    "\n",
    "    for emotion_id, emotion_label in emotions.items():\n",
    "        emotion_dir_name = EMOTION_TO_DIR[emotion_label]\n",
    "        emotion_dir = os.path.join(data_root, emotion_dir_name)\n",
    "        target_text = emotion_label.lower()\n",
    "\n",
    "        for i in range(1, FILES_PER_EMOTION + 1):\n",
    "            file_path = os.path.join(emotion_dir, f\"{emotion_dir_name}_{i}.npy\")\n",
    "            if os.path.exists(file_path):\n",
    "                try:\n",
    "                    features = np.load(file_path)\n",
    "                    if features.ndim != 2 or features.shape[1] != 8:\n",
    "                        logger.warning(f\"Invalid shape in {file_path}: {features.shape}\")\n",
    "                        invalid_files.append(file_path)\n",
    "                        continue\n",
    "\n",
    "                    valid_features = features[~np.any(np.abs(features) >= 1000, axis=1)]\n",
    "                    if valid_features.shape[0] < seq_len:\n",
    "                        logger.warning(f\"Too few samples in {file_path}: {valid_features.shape[0]}\")\n",
    "                        invalid_files.append(file_path)\n",
    "                        continue\n",
    "\n",
    "                    if USE_SLIDING_WINDOW:\n",
    "                        num_sequences = min(samples_per_file, valid_features.shape[0] - seq_len + 1)\n",
    "                        for start_idx in range(num_sequences):\n",
    "                            sequence = valid_features[start_idx:start_idx + seq_len]\n",
    "                            data.append(sequence)\n",
    "                            labels.append(emotion_id)\n",
    "                            target_texts.append(target_text)\n",
    "                    else:\n",
    "                        num_sequences = min(samples_per_file, valid_features.shape[0] // seq_len)\n",
    "                        for _ in range(num_sequences):\n",
    "                            start_idx = np.random.randint(0, valid_features.shape[0] - seq_len + 1)\n",
    "                            sequence = valid_features[start_idx:start_idx + seq_len]\n",
    "                            data.append(sequence)\n",
    "                            labels.append(emotion_id)\n",
    "                            target_texts.append(target_text)\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error loading {file_path}: {e}\")\n",
    "                    invalid_files.append(file_path)\n",
    "            else:\n",
    "                logger.warning(f\"File not found: {file_path}\")\n",
    "                invalid_files.append(file_path)\n",
    "\n",
    "    if not data:\n",
    "        raise ValueError(f\"No valid sequences loaded. Invalid files: {invalid_files}\")\n",
    "\n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "    target_texts = np.array(target_texts)\n",
    "    logger.info(f\"Loaded data shape: {data.shape}, Labels: {len(labels)}, Target texts: {len(target_texts)}\")\n",
    "    return data, labels, target_texts, invalid_files\n",
    "\n",
    "def prepare_dataset(data, labels, target_texts, tokenizer, emotions):\n",
    "    logger.info(\"Preparing dataset...\")\n",
    "\n",
    "    dataset = []\n",
    "    for emg_data, label, text in zip(data, labels, target_texts):\n",
    "        emg_str = \"; \".join([\", \".join(f\"{v:.2e}\" for v in frame) for frame in emg_data])\n",
    "        prompt = f\"\"\"Unvoiced EMG: {emg_str}\n",
    "Prompt: Convert unvoiced EMG embeddings to text describing the emotion. ### Assistant: {text}\"\"\"\n",
    "        dataset.append({\"text\": prompt, \"label\": label, \"target_text\": text})\n",
    "\n",
    "    ds = Dataset.from_list(dataset)\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        encoding = tokenizer(\n",
    "            examples[\"text\"],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=256,\n",
    "            return_tensors=None\n",
    "        )\n",
    "        target_encoding = tokenizer(\n",
    "            examples[\"target_text\"],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=256,\n",
    "            return_tensors=None\n",
    "        )\n",
    "        labels = []\n",
    "        for label_seq in target_encoding[\"input_ids\"]:\n",
    "            label_with_ignore = [\n",
    "                -100 if token_id == tokenizer.pad_token_id else token_id for token_id in label_seq\n",
    "            ]\n",
    "            labels.append(label_with_ignore)\n",
    "\n",
    "        encoding[\"labels\"] = labels\n",
    "        return encoding\n",
    "\n",
    "    tokenized_ds = ds.map(tokenize_function, batched=True)\n",
    "    tokenized_ds = tokenized_ds.add_column(\"emotion_labels\", ds[\"label\"])\n",
    "    tokenized_ds = tokenized_ds.add_column(\"target_texts\", ds[\"target_text\"])\n",
    "\n",
    "    return tokenized_ds.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "def main():\n",
    "    os.makedirs(PROCESSED_DATA_DIR, exist_ok=True)\n",
    "\n",
    "    logger.info(\"Loading tokenizer...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"unsloth/Mistral-Small-3.2-24B-Instruct-2506-unsloth-bnb-4bit\")\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    try:\n",
    "        data, labels, target_texts, invalid_files = load_emg_sequences(\n",
    "            DATA_ROOT, EMOTIONS, SAMPLES_PER_FILE, SEQ_LEN\n",
    "        )\n",
    "    except ValueError as e:\n",
    "        logger.error(f\"Data loading failed: {e}\")\n",
    "        return\n",
    "\n",
    "    dataset = prepare_dataset(data, labels, target_texts, tokenizer, EMOTIONS)\n",
    "\n",
    "    logger.info(\"Saving processed data...\")\n",
    "    try:\n",
    "        dataset[\"train\"].save_to_disk(os.path.join(PROCESSED_DATA_DIR, \"train_dataset\"))\n",
    "        dataset[\"test\"].save_to_disk(os.path.join(PROCESSED_DATA_DIR, \"test_dataset\"))\n",
    "        tokenizer.save_pretrained(os.path.join(PROCESSED_DATA_DIR, \"tokenizer\"))\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saving datasets: {e}\")\n",
    "        return\n",
    "\n",
    "    metadata = {\n",
    "        \"emotions\": EMOTIONS,\n",
    "        \"emotion_to_dir\": EMOTION_TO_DIR,\n",
    "        \"seq_len\": SEQ_LEN,\n",
    "        \"n_train_samples\": len(dataset[\"train\"]),\n",
    "        \"n_test_samples\": len(dataset[\"test\"]),\n",
    "        \"invalid_files\": invalid_files\n",
    "    }\n",
    "    with open(os.path.join(PROCESSED_DATA_DIR, \"metadata.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(metadata, f)\n",
    "\n",
    "    logger.info(f\"Data processing complete! Saved to {PROCESSED_DATA_DIR}\")\n",
    "    logger.info(f\"Train samples: {metadata['n_train_samples']}, Test samples: {metadata['n_test_samples']}\")\n",
    "    if invalid_files:\n",
    "        logger.warning(f\"Invalid files: {invalid_files}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b440430-9a0c-4243-9895-e1e0d0fdebb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2344bfd-cda1-4d99-a5ea-7ce4a6bbba8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mistral_common\n",
      "  Downloading mistral_common-1.6.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: pydantic<3.0,>=2.7 in /home/saihan/miniconda3/lib/python3.12/site-packages (from mistral_common) (2.10.3)\n",
      "Requirement already satisfied: jsonschema>=4.21.1 in /home/saihan/miniconda3/lib/python3.12/site-packages (from mistral_common) (4.23.0)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /home/saihan/miniconda3/lib/python3.12/site-packages (from mistral_common) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.11.0 in /home/saihan/miniconda3/lib/python3.12/site-packages (from mistral_common) (4.13.2)\n",
      "Collecting tiktoken>=0.7.0 (from mistral_common)\n",
      "  Downloading tiktoken-0.9.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: pillow>=10.3.0 in /home/saihan/miniconda3/lib/python3.12/site-packages (from mistral_common) (11.2.1)\n",
      "Requirement already satisfied: requests>=2.0.0 in /home/saihan/miniconda3/lib/python3.12/site-packages (from mistral_common) (2.32.3)\n",
      "Requirement already satisfied: numpy>=1.25 in /home/saihan/miniconda3/lib/python3.12/site-packages (from mistral_common) (2.2.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/saihan/miniconda3/lib/python3.12/site-packages (from jsonschema>=4.21.1->mistral_common) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/saihan/miniconda3/lib/python3.12/site-packages (from jsonschema>=4.21.1->mistral_common) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/saihan/miniconda3/lib/python3.12/site-packages (from jsonschema>=4.21.1->mistral_common) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/saihan/miniconda3/lib/python3.12/site-packages (from jsonschema>=4.21.1->mistral_common) (0.24.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/saihan/miniconda3/lib/python3.12/site-packages (from pydantic<3.0,>=2.7->mistral_common) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /home/saihan/miniconda3/lib/python3.12/site-packages (from pydantic<3.0,>=2.7->mistral_common) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/saihan/miniconda3/lib/python3.12/site-packages (from requests>=2.0.0->mistral_common) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/saihan/miniconda3/lib/python3.12/site-packages (from requests>=2.0.0->mistral_common) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/saihan/miniconda3/lib/python3.12/site-packages (from requests>=2.0.0->mistral_common) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/saihan/miniconda3/lib/python3.12/site-packages (from requests>=2.0.0->mistral_common) (2025.1.31)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/saihan/miniconda3/lib/python3.12/site-packages (from tiktoken>=0.7.0->mistral_common) (2024.11.6)\n",
      "Downloading mistral_common-1.6.2-py3-none-any.whl (6.5 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.9.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tiktoken, mistral_common\n",
      "Successfully installed mistral_common-1.6.2 tiktoken-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mistral_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bb01c1b-e812-4306-b0d0-e7b655d2ca04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.2\n"
     ]
    }
   ],
   "source": [
    "import mistral_common; print(mistral_common.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec5d999-a332-4641-9f90-a43e38f734fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Üí Downloading and caching model/tokenizer...\n",
      "Unsloth: WARNING `trust_remote_code` is True.\n",
      "Are you certain you want to do remote code execution?\n",
      "==((====))==  Unsloth 2025.6.5: Fast Mistral patching. Transformers: 4.52.4.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3050 Laptop GPU. Num GPUs = 1. Max memory: 4.0 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "# download_and_cache.py\n",
    "# Import unsloth first as recommended\n",
    "import unsloth\n",
    "from unsloth import FastLanguageModel\n",
    "from transformers import AutoTokenizer\n",
    "import os\n",
    "\n",
    "# Use the Mistral model you specified\n",
    "MODEL_NAME = \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\"\n",
    "CACHE_MODEL_DIR = \"/home/saihan/.cache/huggingface/hub/models--mistral-7b-instruct-v0.3-bnb-4bit\"\n",
    "MAX_SEQ_LENGTH = 256\n",
    "\n",
    "def download_model_and_tokenizer():\n",
    "    print(\"‚Üí Downloading and caching model/tokenizer...\")\n",
    "    try:\n",
    "        # First try loading from the original model name\n",
    "        model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "            model_name=MODEL_NAME,\n",
    "            max_seq_length=MAX_SEQ_LENGTH,\n",
    "            load_in_4bit=True,\n",
    "            trust_remote_code=True,\n",
    "        )\n",
    "        \n",
    "        # Save both model and tokenizer to cache directory\n",
    "        os.makedirs(CACHE_MODEL_DIR, exist_ok=True)\n",
    "        model.save_pretrained(CACHE_MODEL_DIR)\n",
    "        tokenizer.save_pretrained(CACHE_MODEL_DIR)\n",
    "        print(\"‚úì Model and tokenizer cached!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading model: {e}\")\n",
    "        print(\"You may need to:\")\n",
    "        print(\"1. Check your internet connection\")\n",
    "        print(\"2. Verify the model name is correct\")\n",
    "        print(\"3. Clear the cache directory if it's corrupted\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    download_model_and_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9e7583d-aecb-492b-8b65-6fa8c16620f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0 text type: <class 'str'>, content: Unvoiced EMG: 3.12e-06, -7.81e-07, -9.77e-06, 9.62e-06, -6.25e-06, 2.22e-05, -1.81e-05, 4.55e-05; 1.\n",
      "Sample 1 text type: <class 'str'>, content: Unvoiced EMG: -5.27e-06, -1.12e-05, -8.74e-06, 1.81e-06, -1.42e-05, 5.86e-07, -1.05e-05, -5.03e-06; \n",
      "Sample 2 text type: <class 'str'>, content: Unvoiced EMG: -3.15e-05, -1.37e-05, -8.69e-06, 1.06e-05, -6.64e-06, -5.37e-07, -2.00e-06, 8.40e-06; \n",
      "Sample 3 text type: <class 'str'>, content: Unvoiced EMG: -2.34e-06, -5.57e-06, -1.59e-05, -7.52e-06, -4.93e-06, -9.37e-06, -2.06e-05, -1.11e-05\n",
      "Sample 4 text type: <class 'str'>, content: Unvoiced EMG: 9.18e-06, 1.39e-05, -1.15e-05, -1.46e-06, -1.07e-05, -1.08e-05, -7.81e-06, 1.90e-06; 9\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "ds = load_from_disk(\"/home/saihan/New folder/emg_project/processed_data/train_dataset\")\n",
    "for i in range(min(5, len(ds))):\n",
    "    print(f\"Sample {i} text type: {type(ds[i]['text'])}, content: {ds[i]['text'][:100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fc0f615-4ff4-411b-9f4c-b311a938dbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1552/1277626604.py:8: UserWarning: WARNING: Unsloth should be imported before transformers to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n",
      "\n",
      "Please restructure your imports with 'import unsloth' at the top of your file.\n",
      "  from unsloth import FastLanguageModel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 10:11:30,839 - INFO - Loading test data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Üí Starting evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 10:11:31,983 - INFO - Using 2000 samples\n",
      "2025-06-26 10:11:32,132 - INFO - Loading model and tokenizer...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.6.5: Fast Llama patching. Transformers: 4.52.4.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3050 Laptop GPU. Num GPUs = 1. Max memory: 4.0 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.6.5 patched 16 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n",
      "2025-06-26 10:11:38,253 - INFO - Evaluating model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c04c608b066443aade14f688a1ac403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saihan/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/saihan/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/saihan/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "2025-06-26 10:33:11,637 - INFO - Accuracy = 0.2465\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      1.00      0.40       493\n",
      "           1       0.00      0.00      0.00       507\n",
      "           2       0.00      0.00      0.00       501\n",
      "           3       0.00      0.00      0.00       499\n",
      "\n",
      "    accuracy                           0.25      2000\n",
      "   macro avg       0.06      0.25      0.10      2000\n",
      "weighted avg       0.06      0.25      0.10      2000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Üí Done!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "import logging\n",
    "from datasets import load_from_disk, Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from unsloth import FastLanguageModel\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# CONFIG\n",
    "PROCESSED_DATA_DIR = \"/home/saihan/New folder/emg_project/processed_data\"\n",
    "MODEL_OUTPUT_DIR = \"/home/saihan/New folder/emg_project/trained_model\"\n",
    "RESULT_FILE = os.path.join(MODEL_OUTPUT_DIR, \"evaluation_results.txt\")\n",
    "MAX_SEQ_LENGTH = 256\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "def load_model_and_tokenizer():\n",
    "    logger.info(\"Loading model and tokenizer...\")\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name=MODEL_OUTPUT_DIR,\n",
    "        max_seq_length=MAX_SEQ_LENGTH,\n",
    "        load_in_4bit=True,\n",
    "        device_map=\"auto\",\n",
    "        max_memory={0: \"3.8GB\"}\n",
    "    )\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device).eval()\n",
    "    return model, tokenizer, device\n",
    "\n",
    "def load_test_data():\n",
    "    logger.info(\"Loading test data...\")\n",
    "    dataset = load_from_disk(os.path.join(PROCESSED_DATA_DIR, \"test_dataset\"))\n",
    "    tokenizer = AutoTokenizer.from_pretrained(os.path.join(PROCESSED_DATA_DIR, \"tokenizer\"))\n",
    "    metadata = pickle.load(open(os.path.join(PROCESSED_DATA_DIR, \"metadata.pkl\"), \"rb\"))\n",
    "\n",
    "    required_keys = [\"text\", \"emotion_labels\"]\n",
    "    valid = []\n",
    "    for i, ex in enumerate(dataset):\n",
    "        if any(k not in ex for k in required_keys) or not isinstance(ex[\"text\"], str):\n",
    "            continue\n",
    "        valid.append({\n",
    "            **ex,\n",
    "            \"text\": ex[\"text\"].replace(\"\\n\", \" \").split(\"### Assistant:\")[0] + \"### Assistant:\"\n",
    "        })\n",
    "    if not valid:\n",
    "        raise RuntimeError(\"No valid samples.\")\n",
    "    logger.info(f\"Using {len(valid)} samples\")\n",
    "    return Dataset.from_list(valid), tokenizer, metadata\n",
    "\n",
    "def evaluate_model(model, tokenizer, test_ds, metadata, device):\n",
    "    logger.info(\"Evaluating model\")\n",
    "    predictions, trues = [], []\n",
    "    emotions = [str(em) for em in metadata[\"emotions\"]] \n",
    "    label_map = {em: idx for idx, em in enumerate(emotions)}\n",
    "\n",
    "\n",
    "    for ex in tqdm(test_ds, desc=\"Eval\"):\n",
    "        inputs = tokenizer(\n",
    "            ex[\"text\"], return_tensors=\"pt\",\n",
    "            padding=True, truncation=True, max_length=MAX_SEQ_LENGTH\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=20,\n",
    "                temperature=0.8,\n",
    "                num_beams=1,               # ‚ö†Ô∏è Avoid beam search error\n",
    "                pad_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "\n",
    "        resp = tokenizer.decode(outputs[0], skip_special_tokens=True).lower()\n",
    "        resp = resp.split(\"### Assistant:\")[-1].strip()\n",
    "        pred_idx = max(\n",
    "            ((em, resp.count(em.lower())) for em in emotions),\n",
    "            key=lambda x: x[1]\n",
    "        )[0]\n",
    "        predictions.append(label_map[pred_idx])\n",
    "        trues.append(int(ex[\"emotion_labels\"]))\n",
    "\n",
    "    acc = accuracy_score(trues, predictions)\n",
    "    report = classification_report(trues, predictions, target_names=emotions)\n",
    "    logger.info(f\"Accuracy = {acc:.4f}\\n{report}\")\n",
    "\n",
    "    with open(RESULT_FILE, \"w\") as f:\n",
    "        f.write(f\"Accuracy: {acc:.4f}\\n{report}\")\n",
    "        f.write(\"\\nSample predictions:\\n\")\n",
    "        for t, p in zip(trues[:5], predictions[:5]):\n",
    "            f.write(f\"True: {emotions[t]} -> Pred: {emotions[p]}\\n\")\n",
    "\n",
    "    return acc, report\n",
    "\n",
    "def main():\n",
    "    print(\"‚Üí Starting evaluation\")\n",
    "    test_ds, tokenizer, metadata = load_test_data()\n",
    "    model, tokenizer, device = load_model_and_tokenizer()\n",
    "    evaluate_model(model, tokenizer, test_ds, metadata, device)\n",
    "    print(\"‚Üí Done!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c7cbe36-bf42-424c-bd5c-fc4a0be8bfc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset type: <class 'datasets.arrow_dataset.Dataset'>\n",
      "First 5 samples:\n",
      "Sample 0 type: <class 'dict'>, content: {'text': 'Unvoiced EMG: 1.17e-06, 2.39e-06, 7.81e-06, -1.58e-05, -2.34e-06, -1.21e-05, -7.62e-06, -3.76e-06; 2.49e-06, 5.27e-06, 6.35e-07, -1.22e-06, -1.95e-06, 4.93e-06, 5.91e-06, -4.30e-06; -2.25e-06, -2.54e-06, -7.32e-06, 3.56e-06, -6.69e-06, 1.66e-06, 1.66e-06, -1.56e-06; 2.10e-06, 5.66e-06, 5.66e-06, 5.03e-06, 1.90e-06, 6.54e-06, 2.49e-06, 2.05e-06; 6.49e-06, 1.40e-05, 1.37e-05, 3.17e-06, 7.03e-06, 8.59e-06, 4.83e-06, 4.88e-08; -1.86e-06, -1.46e-06, -1.61e-06, -1.47e-05, -2.20e-06, -1.15e-05, -5.66e-06, -2.64e-06; -5.37e-06, -9.42e-06, -1.34e-05, -1.19e-05, -1.04e-05, -9.23e-06, -7.57e-06, -2.29e-06; 3.91e-07, -2.93e-07, -1.06e-05, 3.61e-06, -1.08e-05, 5.37e-06, -2.20e-06, -3.81e-06; 9.77e-08, 2.93e-07, -5.91e-06, -3.03e-06, -1.10e-05, -3.27e-06, -7.13e-06, -6.35e-06; -7.08e-06, -6.40e-06, -1.14e-05, -4.98e-06, -1.42e-05, -9.77e-06, -1.09e-05, -9.18e-06\\nPrompt: Convert unvoiced EMG embeddings to text describing the emotion. ### Assistant: The detected emotion is neutral', 'label': 3, 'target_text': 'The detected emotion is neutral', 'input_ids': [128000, 1844, 3415, 7725, 17329, 38, 25, 220, 16, 13, 1114, 68, 12, 2705, 11, 220, 17, 13, 2137, 68, 12, 2705, 11, 220, 22, 13, 5932, 68, 12, 2705, 11, 482, 16, 13, 2970, 68, 12, 2304, 11, 482, 17, 13, 1958, 68, 12, 2705, 11, 482, 16, 13, 1691, 68, 12, 2304, 11, 482, 22, 13, 5538, 68, 12, 2705, 11, 482, 18, 13, 4767, 68, 12, 2705, 26, 220, 17, 13, 2491, 68, 12, 2705, 11, 220, 20, 13, 1544, 68, 12, 2705, 11, 220, 21, 13, 1758, 68, 12, 2589, 11, 482, 16, 13, 1313, 68, 12, 2705, 11, 482, 16, 13, 2721, 68, 12, 2705, 11, 220, 19, 13, 6365, 68, 12, 2705, 11, 220, 20, 13, 5925, 68, 12, 2705, 11, 482, 19, 13, 966, 68, 12, 2705, 26, 482, 17, 13, 914, 68, 12, 2705, 11, 482, 17, 13, 4370, 68, 12, 2705, 11, 482, 22, 13, 843, 68, 12, 2705, 11, 220, 18, 13, 3487, 68, 12, 2705, 11, 482, 21, 13, 3076, 68, 12, 2705, 11, 220, 16, 13, 2287, 68, 12, 2705, 11, 220, 16, 13, 2287, 68, 12, 2705, 11, 482, 16, 13, 3487, 68, 12, 2705, 26, 220, 17, 13, 605, 68, 12, 2705, 11, 220, 20, 13, 2287, 68, 12, 2705, 11, 220, 20, 13, 2287, 68, 12, 2705, 11, 220, 20, 13, 2839, 68, 12, 2705, 11, 220, 16, 13, 1954, 68, 12, 2705, 11, 220, 21, 13, 4370, 68, 12, 2705, 11, 220, 17, 13, 2491, 68, 12, 2705, 11, 220], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 128000, 791, 16914, 20356, 374, 21277], 'emotion_labels': 3, 'target_texts': 'The detected emotion is neutral'}\n",
      "Sample 0 keys: ['text', 'label', 'target_text', 'input_ids', 'attention_mask', 'labels', 'emotion_labels', 'target_texts']\n",
      "Sample 1 type: <class 'dict'>, content: {'text': 'Unvoiced EMG: 2.10e-06, 8.06e-06, 5.13e-06, 9.13e-06, 8.06e-06, 1.07e-05, 3.91e-07, 7.67e-06; 1.66e-06, 6.88e-06, 6.54e-06, 6.40e-06, 9.28e-06, 8.20e-06, 1.49e-05, 9.08e-06; -2.20e-06, 1.10e-05, 7.47e-06, 9.03e-06, 9.47e-06, 1.11e-05, 1.47e-05, 6.54e-06; -4.83e-06, 6.01e-06, 4.00e-06, 5.71e-06, 5.81e-06, 7.57e-06, -1.76e-06, 4.20e-06; -4.25e-06, -1.12e-06, 1.46e-06, 9.28e-07, 4.59e-06, 3.12e-06, -1.81e-06, 2.69e-06; -5.18e-06, 1.66e-06, 1.12e-06, 3.08e-06, 6.25e-06, 5.96e-06, 4.64e-06, 3.42e-07; -3.81e-06, 2.98e-06, 1.71e-06, 3.42e-06, 5.37e-06, 3.37e-06, -5.08e-06, 6.84e-07; -3.42e-07, -1.95e-07, 3.76e-06, 1.12e-06, 4.83e-06, -5.86e-07, -2.78e-06, 4.59e-06; 5.37e-07, 2.49e-06, 5.47e-06, 4.00e-06, 6.25e-06, 5.96e-06, 1.23e-05, 3.81e-06; 1.95e-07, 6.01e-06, 4.54e-06, 8.06e-06, 5.96e-06, 9.77e-06, 7.42e-06, 7.81e-07\\nPrompt: Convert unvoiced EMG embeddings to text describing the emotion. ### Assistant: The detected emotion is neutral', 'label': 3, 'target_text': 'The detected emotion is neutral', 'input_ids': [128000, 1844, 3415, 7725, 17329, 38, 25, 220, 17, 13, 605, 68, 12, 2705, 11, 220, 23, 13, 2705, 68, 12, 2705, 11, 220, 20, 13, 1032, 68, 12, 2705, 11, 220, 24, 13, 1032, 68, 12, 2705, 11, 220, 23, 13, 2705, 68, 12, 2705, 11, 220, 16, 13, 2589, 68, 12, 2304, 11, 220, 18, 13, 5925, 68, 12, 2589, 11, 220, 22, 13, 3080, 68, 12, 2705, 26, 220, 16, 13, 2287, 68, 12, 2705, 11, 220, 21, 13, 2421, 68, 12, 2705, 11, 220, 21, 13, 4370, 68, 12, 2705, 11, 220, 21, 13, 1272, 68, 12, 2705, 11, 220, 24, 13, 1591, 68, 12, 2705, 11, 220, 23, 13, 508, 68, 12, 2705, 11, 220, 16, 13, 2491, 68, 12, 2304, 11, 220, 24, 13, 2318, 68, 12, 2705, 26, 482, 17, 13, 508, 68, 12, 2705, 11, 220, 16, 13, 605, 68, 12, 2304, 11, 220, 22, 13, 2618, 68, 12, 2705, 11, 220, 24, 13, 2839, 68, 12, 2705, 11, 220, 24, 13, 2618, 68, 12, 2705, 11, 220, 16, 13, 806, 68, 12, 2304, 11, 220, 16, 13, 2618, 68, 12, 2304, 11, 220, 21, 13, 4370, 68, 12, 2705, 26, 482, 19, 13, 6069, 68, 12, 2705, 11, 220, 21, 13, 1721, 68, 12, 2705, 11, 220, 19, 13, 410, 68, 12, 2705, 11, 220, 20, 13, 6028, 68, 12, 2705, 11, 220, 20, 13, 5932, 68, 12, 2705, 11, 220, 22, 13, 3226, 68, 12, 2705, 11, 482, 16, 13, 4767, 68, 12, 2705, 11, 220], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 128000, 791, 16914, 20356, 374, 21277], 'emotion_labels': 3, 'target_texts': 'The detected emotion is neutral'}\n",
      "Sample 1 keys: ['text', 'label', 'target_text', 'input_ids', 'attention_mask', 'labels', 'emotion_labels', 'target_texts']\n",
      "Sample 2 type: <class 'dict'>, content: {'text': 'Unvoiced EMG: -2.14e-05, -3.42e-07, -8.45e-05, -8.48e-05, -1.12e-04, -1.01e-05, -7.50e-05, -7.91e-06; 1.90e-05, 4.41e-05, -6.81e-05, -4.02e-05, -8.53e-05, -3.14e-05, -5.30e-05, 4.01e-05; 3.78e-05, 4.81e-05, 5.18e-06, 9.23e-06, 1.74e-05, 5.39e-05, 7.03e-05, 3.16e-05; 4.11e-05, 2.98e-05, 1.31e-05, 2.19e-05, 8.47e-05, 1.50e-04, 1.61e-06, 1.82e-05; 3.03e-05, 1.47e-05, -7.07e-05, 3.19e-05, 6.36e-05, 1.40e-04, 2.24e-05, 2.21e-05; -8.94e-06, -9.23e-06, -6.68e-05, 2.79e-05, 1.44e-05, 6.67e-05, 3.50e-04, -1.74e-05; -3.99e-05, -3.74e-05, 2.50e-05, 3.08e-06, -2.00e-05, -1.98e-05, 2.66e-04, -5.92e-05; -3.97e-05, -5.15e-05, 4.82e-05, -1.20e-05, -2.70e-05, -4.44e-05, -9.44e-05, -5.59e-05; -3.10e-05, -3.40e-05, -2.98e-06, 4.54e-06, -4.44e-05, -3.91e-07, -5.76e-05, -5.21e-05; -2.62e-05, -1.71e-05, -4.87e-05, 2.60e-05, -8.28e-05, 3.06e-05, -1.17e-04, -5.47e-05\\nPrompt: Convert unvoiced EMG embeddings to text describing the emotion. ### Assistant: The detected emotion is happy', 'label': 0, 'target_text': 'The detected emotion is happy', 'input_ids': [128000, 1844, 3415, 7725, 17329, 38, 25, 482, 17, 13, 975, 68, 12, 2304, 11, 482, 18, 13, 2983, 68, 12, 2589, 11, 482, 23, 13, 1774, 68, 12, 2304, 11, 482, 23, 13, 2166, 68, 12, 2304, 11, 482, 16, 13, 717, 68, 12, 2371, 11, 482, 16, 13, 1721, 68, 12, 2304, 11, 482, 22, 13, 1135, 68, 12, 2304, 11, 482, 22, 13, 5925, 68, 12, 2705, 26, 220, 16, 13, 1954, 68, 12, 2304, 11, 220, 19, 13, 3174, 68, 12, 2304, 11, 482, 21, 13, 5932, 68, 12, 2304, 11, 482, 19, 13, 2437, 68, 12, 2304, 11, 482, 23, 13, 4331, 68, 12, 2304, 11, 482, 18, 13, 975, 68, 12, 2304, 11, 482, 20, 13, 966, 68, 12, 2304, 11, 220, 19, 13, 1721, 68, 12, 2304, 26, 220, 18, 13, 2495, 68, 12, 2304, 11, 220, 19, 13, 5932, 68, 12, 2304, 11, 220, 20, 13, 972, 68, 12, 2705, 11, 220, 24, 13, 1419, 68, 12, 2705, 11, 220, 16, 13, 5728, 68, 12, 2304, 11, 220, 20, 13, 2137, 68, 12, 2304, 11, 220, 22, 13, 2839, 68, 12, 2304, 11, 220, 18, 13, 845, 68, 12, 2304, 26, 220, 19, 13, 806, 68, 12, 2304, 11, 220, 17, 13, 3264, 68, 12, 2304, 11, 220, 16, 13, 2148, 68, 12, 2304, 11, 220, 17, 13, 777, 68, 12, 2304, 11, 220, 23, 13, 2618, 68, 12, 2304, 11, 220, 16, 13, 1135, 68, 12, 2371, 11, 220, 16, 13, 5547, 68, 12, 2705, 11, 220], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 128000, 791, 16914, 20356, 374, 6380], 'emotion_labels': 0, 'target_texts': 'The detected emotion is happy'}\n",
      "Sample 2 keys: ['text', 'label', 'target_text', 'input_ids', 'attention_mask', 'labels', 'emotion_labels', 'target_texts']\n",
      "Sample 3 type: <class 'dict'>, content: {'text': 'Unvoiced EMG: -1.44e-05, -1.62e-05, -4.69e-06, -1.89e-05, -1.06e-05, -1.40e-05, -4.44e-06, -1.45e-05; -1.39e-05, -1.50e-05, -5.22e-06, -5.03e-06, -1.03e-05, -1.05e-05, -2.64e-06, -2.25e-05; -1.14e-05, -1.62e-05, 3.17e-06, 1.95e-06, -3.91e-06, -9.33e-06, -1.27e-06, -1.86e-05; -5.22e-06, -7.23e-06, 1.10e-05, -1.71e-06, 3.66e-06, -2.83e-06, 7.37e-06, -3.81e-06; 3.66e-06, 8.15e-06, 1.64e-05, 4.83e-06, 9.86e-06, 9.57e-06, 2.13e-05, 4.49e-06; 7.52e-06, 1.24e-05, 1.91e-05, 1.89e-05, 1.34e-05, 1.82e-05, 2.40e-05, 3.47e-06; 1.37e-05, 1.61e-05, 2.18e-05, 1.90e-05, 1.64e-05, 1.71e-05, 1.79e-05, 1.30e-05; 1.33e-05, 1.54e-05, 1.90e-05, 9.77e-06, 1.23e-05, 3.22e-06, 8.45e-06, 1.36e-05; 5.22e-06, 8.50e-06, 1.06e-05, 1.07e-05, 2.93e-07, -4.54e-06, 2.44e-07, 6.25e-06; 3.66e-06, 5.66e-06, 7.96e-06, 5.18e-06, -5.47e-06, -3.22e-06, 3.96e-06, 9.57e-06\\nPrompt: Convert unvoiced EMG embeddings to text describing the emotion. ### Assistant: The detected emotion is neutral', 'label': 3, 'target_text': 'The detected emotion is neutral', 'input_ids': [128000, 1844, 3415, 7725, 17329, 38, 25, 482, 16, 13, 2096, 68, 12, 2304, 11, 482, 16, 13, 5538, 68, 12, 2304, 11, 482, 19, 13, 3076, 68, 12, 2705, 11, 482, 16, 13, 4578, 68, 12, 2304, 11, 482, 16, 13, 2705, 68, 12, 2304, 11, 482, 16, 13, 1272, 68, 12, 2304, 11, 482, 19, 13, 2096, 68, 12, 2705, 11, 482, 16, 13, 1774, 68, 12, 2304, 26, 482, 16, 13, 2137, 68, 12, 2304, 11, 482, 16, 13, 1135, 68, 12, 2304, 11, 482, 20, 13, 1313, 68, 12, 2705, 11, 482, 20, 13, 2839, 68, 12, 2705, 11, 482, 16, 13, 2839, 68, 12, 2304, 11, 482, 16, 13, 2304, 68, 12, 2304, 11, 482, 17, 13, 1227, 68, 12, 2705, 11, 482, 17, 13, 914, 68, 12, 2304, 26, 482, 16, 13, 975, 68, 12, 2304, 11, 482, 16, 13, 5538, 68, 12, 2304, 11, 220, 18, 13, 1114, 68, 12, 2705, 11, 220, 16, 13, 2721, 68, 12, 2705, 11, 482, 18, 13, 5925, 68, 12, 2705, 11, 482, 24, 13, 1644, 68, 12, 2705, 11, 482, 16, 13, 1544, 68, 12, 2705, 11, 482, 16, 13, 4218, 68, 12, 2304, 26, 482, 20, 13, 1313, 68, 12, 2705, 11, 482, 22, 13, 1419, 68, 12, 2705, 11, 220, 16, 13, 605, 68, 12, 2304, 11, 482, 16, 13, 6028, 68, 12, 2705, 11, 220, 18, 13, 2287, 68, 12, 2705, 11, 482, 17, 13, 6069, 68, 12, 2705, 11, 220, 22, 13, 1806, 68, 12, 2705, 11, 482], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 128000, 791, 16914, 20356, 374, 21277], 'emotion_labels': 3, 'target_texts': 'The detected emotion is neutral'}\n",
      "Sample 3 keys: ['text', 'label', 'target_text', 'input_ids', 'attention_mask', 'labels', 'emotion_labels', 'target_texts']\n",
      "Sample 4 type: <class 'dict'>, content: {'text': 'Unvoiced EMG: -7.57e-06, 5.18e-05, 2.78e-05, 2.36e-05, 3.02e-05, 1.15e-05, 5.24e-04, 1.93e-05; -1.93e-05, 5.87e-05, 1.07e-05, 1.20e-05, 1.39e-05, 1.51e-06, 5.38e-04, -9.28e-07; -1.02e-05, 1.10e-05, 1.12e-06, 6.10e-06, 5.66e-06, 3.52e-06, 2.59e-04, -1.81e-05; -4.35e-06, -6.00e-05, -2.44e-06, 1.03e-06, 1.22e-05, -3.96e-06, 5.93e-05, -3.32e-06; 2.34e-06, -5.00e-05, 1.10e-05, 1.32e-05, 2.84e-05, -2.78e-06, 2.49e-04, 3.36e-05; 1.02e-05, 1.66e-05, 3.53e-05, 3.17e-05, 3.24e-05, 1.59e-05, 4.13e-04, 4.25e-05; -4.88e-06, 5.08e-05, 3.05e-05, 2.20e-05, 1.72e-05, 1.39e-05, 3.47e-04, 4.25e-06; -2.15e-05, 3.86e-05, 9.91e-06, 7.18e-06, 6.88e-06, 4.88e-07, 3.09e-04, -1.28e-05; -2.61e-05, 6.84e-07, 4.54e-06, 5.81e-06, 1.03e-05, 6.84e-07, 3.40e-04, -2.05e-06; -1.91e-05, -3.72e-05, 1.68e-05, 7.08e-06, 1.98e-05, 4.25e-06, 3.58e-04, 2.00e-06\\nPrompt: Convert unvoiced EMG embeddings to text describing the emotion. ### Assistant: The detected emotion is sad', 'label': 1, 'target_text': 'The detected emotion is sad', 'input_ids': [128000, 1844, 3415, 7725, 17329, 38, 25, 482, 22, 13, 3226, 68, 12, 2705, 11, 220, 20, 13, 972, 68, 12, 2304, 11, 220, 17, 13, 2495, 68, 12, 2304, 11, 220, 17, 13, 1927, 68, 12, 2304, 11, 220, 18, 13, 2437, 68, 12, 2304, 11, 220, 16, 13, 868, 68, 12, 2304, 11, 220, 20, 13, 1187, 68, 12, 2371, 11, 220, 16, 13, 6365, 68, 12, 2304, 26, 482, 16, 13, 6365, 68, 12, 2304, 11, 220, 20, 13, 4044, 68, 12, 2304, 11, 220, 16, 13, 2589, 68, 12, 2304, 11, 220, 16, 13, 508, 68, 12, 2304, 11, 220, 16, 13, 2137, 68, 12, 2304, 11, 220, 16, 13, 3971, 68, 12, 2705, 11, 220, 20, 13, 1987, 68, 12, 2371, 11, 482, 24, 13, 1591, 68, 12, 2589, 26, 482, 16, 13, 2437, 68, 12, 2304, 11, 220, 16, 13, 605, 68, 12, 2304, 11, 220, 16, 13, 717, 68, 12, 2705, 11, 220, 21, 13, 605, 68, 12, 2705, 11, 220, 20, 13, 2287, 68, 12, 2705, 11, 220, 18, 13, 4103, 68, 12, 2705, 11, 220, 17, 13, 2946, 68, 12, 2371, 11, 482, 16, 13, 5932, 68, 12, 2304, 26, 482, 19, 13, 1758, 68, 12, 2705, 11, 482, 21, 13, 410, 68, 12, 2304, 11, 482, 17, 13, 2096, 68, 12, 2705, 11, 220, 16, 13, 2839, 68, 12, 2705, 11, 220, 16, 13, 1313, 68, 12, 2304, 11, 482, 18, 13, 4161, 68, 12, 2705, 11, 220, 20, 13, 6365, 68, 12, 2304, 11, 482], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 128000, 791, 16914, 20356, 374, 12703], 'emotion_labels': 1, 'target_texts': 'The detected emotion is sad'}\n",
      "Sample 4 keys: ['text', 'label', 'target_text', 'input_ids', 'attention_mask', 'labels', 'emotion_labels', 'target_texts']\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "ds = load_from_disk('/home/saihan/New folder/emg_project/processed_data/test_dataset')\n",
    "print(f'Dataset type: {type(ds)}')\n",
    "print(f'First 5 samples:')\n",
    "for i in range(min(5, len(ds))):\n",
    "    print(f'Sample {i} type: {type(ds[i])}, content: {ds[i] if isinstance(ds[i], dict) else ds[i][:100]}')\n",
    "    if isinstance(ds[i], dict):\n",
    "        print(f'Sample {i} keys: {list(ds[i].keys())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c1a5531-4e46-463b-8d07-07fbc53e4a55",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trues' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     30\u001b[39m     plt.show()\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Call these after predictions\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m plot_confusion_matrix(\u001b[43mtrues\u001b[49m, predictions, class_names=[\u001b[33m\"\u001b[39m\u001b[33m0\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m2\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m3\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     34\u001b[39m plot_classification_report(trues, predictions, class_names=[\u001b[33m\"\u001b[39m\u001b[33m0\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m2\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m3\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'trues' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    disp.plot(ax=ax, cmap=\"Blues\", values_format='d')\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_classification_report(y_true, y_pred, class_names):\n",
    "    report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
    "    \n",
    "    metrics = ['precision', 'recall', 'f1-score']\n",
    "    data = {metric: [report[str(i)][metric] for i in range(len(class_names))] for metric in metrics}\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    for idx, metric in enumerate(metrics):\n",
    "        sns.barplot(x=class_names, y=data[metric], ax=axs[idx], palette='viridis')\n",
    "        axs[idx].set_ylim(0, 1)\n",
    "        axs[idx].set_title(f'{metric.capitalize()} per Class')\n",
    "        axs[idx].set_ylabel(metric)\n",
    "        axs[idx].set_xlabel('Class')\n",
    "\n",
    "    plt.suptitle(\"Classification Metrics per Class\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call these after predictions\n",
    "plot_confusion_matrix(trues, predictions, class_names=[\"0\", \"1\", \"2\", \"3\"])\n",
    "plot_classification_report(trues, predictions, class_names=[\"0\", \"1\", \"2\", \"3\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1967b058-2376-4805-8a41-f75fb66f3799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "features = np.load('/home/saihan/New folder/data/fear/fear_1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "239f9694-4ced-43b7-88cb-063eb9651847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.0000000e+03, -1.0000000e+03, -1.0000000e+03, ...,\n",
       "        -1.0000000e+03, -1.0000000e+03, -1.0000000e+03],\n",
       "       [-1.0000000e+03, -1.0000000e+03, -1.0000000e+03, ...,\n",
       "        -1.0000000e+03, -1.0000000e+03, -1.0000000e+03],\n",
       "       [-1.0000000e+03, -1.0000000e+03, -1.0000000e+03, ...,\n",
       "        -1.0000000e+03, -1.0000000e+03, -1.0000000e+03],\n",
       "       ...,\n",
       "       [ 2.7978514e-05,  1.9921874e-05,  1.2353516e-05, ...,\n",
       "         3.1542968e-05,  5.7080077e-05,  1.8310546e-05],\n",
       "       [ 1.2548828e-05,  3.7353515e-05, -8.6425780e-06, ...,\n",
       "         3.2812499e-05,  2.4267578e-05,  4.2480469e-06],\n",
       "       [-1.4941405e-05,  4.7851561e-05, -2.4755858e-05, ...,\n",
       "         3.0761719e-06,  7.4365234e-05, -3.5644530e-06]],\n",
       "      shape=(45031, 8), dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd9cc566-9be0-4b77-a062-a4e433860952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting darts\n",
      "  Downloading darts-0.35.0-py3-none-any.whl.metadata (56 kB)\n",
      "Collecting holidays>=0.11.1 (from darts)\n",
      "  Downloading holidays-0.75-py3-none-any.whl.metadata (41 kB)\n",
      "Requirement already satisfied: joblib>=0.16.0 in /home/saihan/miniconda3/lib/python3.12/site-packages (from darts) (1.4.2)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /home/saihan/miniconda3/lib/python3.12/site-packages (from darts) (3.10.1)\n",
      "Collecting narwhals>=1.25.1 (from darts)\n",
      "  Downloading narwhals-1.44.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nfoursid>=1.0.0 (from darts)\n",
      "  Downloading nfoursid-1.0.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/saihan/miniconda3/lib/python3.12/site-packages (from darts) (2.2.5)\n",
      "Requirement already satisfied: pandas>=1.0.5 in /home/saihan/miniconda3/lib/python3.12/site-packages (from darts) (2.2.3)\n",
      "Collecting pyod>=0.9.5 (from darts)\n",
      "  Downloading pyod-2.0.5-py3-none-any.whl.metadata (46 kB)\n",
      "Requirement already satisfied: requests>=2.22.0 in /home/saihan/miniconda3/lib/python3.12/site-packages (from darts) (2.32.3)\n",
      "Requirement already satisfied: scikit-learn>=1.6.0 in /home/saihan/miniconda3/lib/python3.12/site-packages (from darts) (1.7.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/saihan/miniconda3/lib/python3.12/site-packages (from darts) (1.15.2)\n",
      "Collecting shap>=0.40.0 (from darts)\n",
      "  Downloading shap-0.48.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
      "Collecting statsforecast>=1.4 (from darts)\n",
      "  Downloading statsforecast-2.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (29 kB)\n",
      "Collecting statsmodels>=0.14.0 (from darts)\n",
      "  Downloading statsmodels-0.14.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: tqdm>=4.60.0 in /home/saihan/miniconda3/lib/python3.12/site-packages (from darts) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in /home/saihan/miniconda3/lib/python3.12/site-packages (from darts) (4.13.2)\n",
      "Collecting xarray>=0.17.0 (from darts)\n",
      "  Downloading xarray-2025.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting xgboost>=2.1.4 (from darts)\n",
      "  Downloading xgboost-3.0.2-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting pytorch-lightning>=1.5.0 (from darts)\n",
      "  Downloading pytorch_lightning-2.5.2-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting tensorboardX>=2.1 (from darts)\n",
      "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: torch>=1.8.0 in /home/saihan/miniconda3/lib/python3.12/site-packages (from darts) (2.6.0)\n",
      "Requirement already satisfied: python-dateutil in /home/saihan/miniconda3/lib/python3.12/site-packages (from holidays>=0.11.1->darts) (2.9.0.post0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/saihan/miniconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->darts) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/saihan/miniconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->darts) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/saihan/miniconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->darts) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/saihan/miniconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->darts) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/saihan/miniconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->darts) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/saihan/miniconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->darts) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/saihan/miniconda3/lib/python3.12/site-packages (from matplotlib>=3.3.0->darts) (3.2.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/saihan/miniconda3/lib/python3.12/site-packages (from pandas>=1.0.5->darts) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/saihan/miniconda3/lib/python3.12/site-packages (from pandas>=1.0.5->darts) (2025.2)\n",
      "Collecting numba>=0.51 (from pyod>=0.9.5->darts)\n",
      "  Downloading numba-0.61.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /home/saihan/miniconda3/lib/python3.12/site-packages (from pytorch-lightning>=1.5.0->darts) (6.0.2)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in /home/saihan/miniconda3/lib/python3.12/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (2024.12.0)\n",
      "Collecting torchmetrics>=0.7.0 (from pytorch-lightning>=1.5.0->darts)\n",
      "  Downloading torchmetrics-1.7.3-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning>=1.5.0->darts)\n",
      "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/saihan/miniconda3/lib/python3.12/site-packages (from requests>=2.22.0->darts) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/saihan/miniconda3/lib/python3.12/site-packages (from requests>=2.22.0->darts) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/saihan/miniconda3/lib/python3.12/site-packages (from requests>=2.22.0->darts) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/saihan/miniconda3/lib/python3.12/site-packages (from requests>=2.22.0->darts) (2025.1.31)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/saihan/miniconda3/lib/python3.12/site-packages (from scikit-learn>=1.6.0->darts) (3.6.0)\n",
      "Collecting slicer==0.0.8 (from shap>=0.40.0->darts)\n",
      "  Downloading slicer-0.0.8-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting cloudpickle (from shap>=0.40.0->darts)\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting coreforecast>=0.0.12 (from statsforecast>=1.4->darts)\n",
      "  Downloading coreforecast-0.0.16-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting fugue>=0.8.1 (from statsforecast>=1.4->darts)\n",
      "  Downloading fugue-0.9.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting utilsforecast>=0.1.4 (from statsforecast>=1.4->darts)\n",
      "  Downloading utilsforecast-0.2.12-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting patsy>=0.5.6 (from statsmodels>=0.14.0->darts)\n",
      "  Downloading patsy-1.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: protobuf>=3.20 in /home/saihan/miniconda3/lib/python3.12/site-packages (from tensorboardX>=2.1->darts) (3.20.3)\n",
      "Requirement already satisfied: filelock in /home/saihan/miniconda3/lib/python3.12/site-packages (from torch>=1.8.0->darts) (3.18.0)\n",
      "Requirement already satisfied: networkx in /home/saihan/miniconda3/lib/python3.12/site-packages (from torch>=1.8.0->darts) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/saihan/miniconda3/lib/python3.12/site-packages (from torch>=1.8.0->darts) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/saihan/miniconda3/lib/python3.12/site-packages (from torch>=1.8.0->darts) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/saihan/miniconda3/lib/python3.12/site-packages (from torch>=1.8.0->darts) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/saihan/miniconda3/lib/python3.12/site-packages (from torch>=1.8.0->darts) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/saihan/miniconda3/lib/python3.12/site-packages (from torch>=1.8.0->darts) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/saihan/miniconda3/lib/python3.12/site-packages (from torch>=1.8.0->darts) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/saihan/miniconda3/lib/python3.12/site-packages (from torch>=1.8.0->darts) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/saihan/miniconda3/lib/python3.12/site-packages (from torch>=1.8.0->darts) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/saihan/miniconda3/lib/python3.12/site-packages (from torch>=1.8.0->darts) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/saihan/miniconda3/lib/python3.12/site-packages (from torch>=1.8.0->darts) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/saihan/miniconda3/lib/python3.12/site-packages (from torch>=1.8.0->darts) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/saihan/miniconda3/lib/python3.12/site-packages (from torch>=1.8.0->darts) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/saihan/miniconda3/lib/python3.12/site-packages (from torch>=1.8.0->darts) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/saihan/miniconda3/lib/python3.12/site-packages (from torch>=1.8.0->darts) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/saihan/miniconda3/lib/python3.12/site-packages (from torch>=1.8.0->darts) (3.2.0)\n",
      "Requirement already satisfied: setuptools in /home/saihan/miniconda3/lib/python3.12/site-packages (from torch>=1.8.0->darts) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/saihan/miniconda3/lib/python3.12/site-packages (from torch>=1.8.0->darts) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/saihan/miniconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.8.0->darts) (1.3.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/saihan/miniconda3/lib/python3.12/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (3.11.17)\n",
      "Collecting triad>=0.9.7 (from fugue>=0.8.1->statsforecast>=1.4->darts)\n",
      "  Downloading triad-0.9.8-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting adagio>=0.2.4 (from fugue>=0.8.1->statsforecast>=1.4->darts)\n",
      "  Downloading adagio-0.2.6-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba>=0.51->pyod>=0.9.5->darts)\n",
      "  Downloading llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/saihan/miniconda3/lib/python3.12/site-packages (from python-dateutil->holidays>=0.11.1->darts) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/saihan/miniconda3/lib/python3.12/site-packages (from jinja2->torch>=1.8.0->darts) (3.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/saihan/miniconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/saihan/miniconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/saihan/miniconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/saihan/miniconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/saihan/miniconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/saihan/miniconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/saihan/miniconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (1.20.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.1 in /home/saihan/miniconda3/lib/python3.12/site-packages (from triad>=0.9.7->fugue>=0.8.1->statsforecast>=1.4->darts) (19.0.1)\n",
      "Collecting fs (from triad>=0.9.7->fugue>=0.8.1->statsforecast>=1.4->darts)\n",
      "  Downloading fs-2.4.16-py2.py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting appdirs~=1.4.3 (from fs->triad>=0.9.7->fugue>=0.8.1->statsforecast>=1.4->darts)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Downloading darts-0.35.0-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading holidays-0.75-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading narwhals-1.44.0-py3-none-any.whl (365 kB)\n",
      "Downloading nfoursid-1.0.1-py3-none-any.whl (16 kB)\n",
      "Downloading pyod-2.0.5-py3-none-any.whl (200 kB)\n",
      "Downloading pytorch_lightning-2.5.2-py3-none-any.whl (825 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m825.4/825.4 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shap-0.48.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading slicer-0.0.8-py3-none-any.whl (15 kB)\n",
      "Downloading statsforecast-2.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (353 kB)\n",
      "Downloading statsmodels-0.14.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.7 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
      "Downloading xarray-2025.6.1-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xgboost-3.0.2-py3-none-manylinux_2_28_x86_64.whl (253.9 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m253.9/253.9 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading coreforecast-0.0.16-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
      "Downloading fugue-0.9.1-py3-none-any.whl (278 kB)\n",
      "Downloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
      "Downloading numba-0.61.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.9 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
      "Downloading torchmetrics-1.7.3-py3-none-any.whl (962 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m962.6/962.6 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading utilsforecast-0.2.12-py3-none-any.whl (42 kB)\n",
      "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading adagio-0.2.6-py3-none-any.whl (19 kB)\n",
      "Downloading llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading triad-0.9.8-py3-none-any.whl (62 kB)\n",
      "Downloading fs-2.4.16-py2.py3-none-any.whl (135 kB)\n",
      "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Installing collected packages: appdirs, tensorboardX, slicer, patsy, narwhals, llvmlite, lightning-utilities, fs, coreforecast, cloudpickle, xgboost, numba, holidays, xarray, utilsforecast, triad, statsmodels, shap, pyod, nfoursid, torchmetrics, adagio, pytorch-lightning, fugue, statsforecast, darts\n",
      "Successfully installed adagio-0.2.6 appdirs-1.4.4 cloudpickle-3.1.1 coreforecast-0.0.16 darts-0.35.0 fs-2.4.16 fugue-0.9.1 holidays-0.75 lightning-utilities-0.14.3 llvmlite-0.44.0 narwhals-1.44.0 nfoursid-1.0.1 numba-0.61.2 patsy-1.0.1 pyod-2.0.5 pytorch-lightning-2.5.2 shap-0.48.0 slicer-0.0.8 statsforecast-2.0.1 statsmodels-0.14.4 tensorboardX-2.6.4 torchmetrics-1.7.3 triad-0.9.8 utilsforecast-0.2.12 xarray-2025.6.1 xgboost-3.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install darts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655ea16d-29c2-4eed-81c1-025d719ce78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "/home/saihan/New folder/data/fear/fear_1.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76199568-1cda-4da2-8df4-f5f148c49324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded EMG data shape: (45031, 8)\n",
      "Missing values filled\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/saihan/miniconda3/lib/python3.12/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | res_blocks      | ModuleList       | 5.4 K  | train\n",
      "-------------------------------------------------------------\n",
      "5.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.4 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n",
      "94        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baf31426dad04b248887de932cac48bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:48\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:599\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    593\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    594\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    595\u001b[39m     ckpt_path,\n\u001b[32m    596\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    597\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    598\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:1012\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m   1011\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m   1016\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:1056\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1055\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.set_detect_anomaly(\u001b[38;5;28mself\u001b[39m._detect_anomaly):\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:216\u001b[39m, in \u001b[36m_FitLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_start()\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:455\u001b[39m, in \u001b[36m_FitLoop.advance\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepoch_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py:152\u001b[39m, in \u001b[36m_TrainingEpochLoop.run\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    153\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_advance_end(data_fetcher)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py:344\u001b[39m, in \u001b[36m_TrainingEpochLoop.advance\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    342\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer.lightning_module.automatic_optimization:\n\u001b[32m    343\u001b[39m     \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m     batch_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mautomatic_optimization\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py:192\u001b[39m, in \u001b[36m_AutomaticOptimization.run\u001b[39m\u001b[34m(self, optimizer, batch_idx, kwargs)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[32m    190\u001b[39m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    194\u001b[39m result = closure.consume_result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py:270\u001b[39m, in \u001b[36m_AutomaticOptimization._optimizer_step\u001b[39m\u001b[34m(self, batch_idx, train_step_and_backward_closure)\u001b[39m\n\u001b[32m    269\u001b[39m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moptimizer_step\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:176\u001b[39m, in \u001b[36m_call_lightning_module_hook\u001b[39m\u001b[34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pytorch_lightning/core/module.py:1328\u001b[39m, in \u001b[36mLightningModule.optimizer_step\u001b[39m\u001b[34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[39m\n\u001b[32m   1304\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[32m   1305\u001b[39m \u001b[33;03mthe optimizer.\u001b[39;00m\n\u001b[32m   1306\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1326\u001b[39m \n\u001b[32m   1327\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1328\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py:154\u001b[39m, in \u001b[36mLightningOptimizer.step\u001b[39m\u001b[34m(self, closure, **kwargs)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_strategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[38;5;28mself\u001b[39m._on_after_step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py:239\u001b[39m, in \u001b[36mStrategy.optimizer_step\u001b[39m\u001b[34m(self, optimizer, closure, model, **kwargs)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl.LightningModule)\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprecision_plugin\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py:123\u001b[39m, in \u001b[36mPrecision.optimizer_step\u001b[39m\u001b[34m(self, optimizer, model, closure, **kwargs)\u001b[39m\n\u001b[32m    122\u001b[39m closure = partial(\u001b[38;5;28mself\u001b[39m._wrap_closure, model, optimizer, closure)\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/optim/optimizer.py:493\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    489\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    490\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    491\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/optim/optimizer.py:91\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     90\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/optim/adam.py:223\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    222\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.enable_grad():\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m         loss = \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.param_groups:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py:109\u001b[39m, in \u001b[36mPrecision._wrap_closure\u001b[39m\u001b[34m(self, model, optimizer, closure)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[33;03mhook is called.\u001b[39;00m\n\u001b[32m    104\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    107\u001b[39m \n\u001b[32m    108\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m closure_result = \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[38;5;28mself\u001b[39m._after_closure(model, optimizer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py:146\u001b[39m, in \u001b[36mClosure.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> Optional[Tensor]:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     \u001b[38;5;28mself\u001b[39m._result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result.loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py:140\u001b[39m, in \u001b[36mClosure.closure\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m step_output.closure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_backward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_output\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclosure_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py:241\u001b[39m, in \u001b[36m_AutomaticOptimization._make_backward_fn.<locals>.backward_fn\u001b[39m\u001b[34m(loss)\u001b[39m\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mbackward_fn\u001b[39m(loss: Tensor) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m     \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbackward\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:328\u001b[39m, in \u001b[36m_call_strategy_hook\u001b[39m\u001b[34m(trainer, hook_name, *args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer.strategy.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py:213\u001b[39m, in \u001b[36mStrategy.backward\u001b[39m\u001b[34m(self, closure_loss, optimizer, *args, **kwargs)\u001b[39m\n\u001b[32m    211\u001b[39m closure_loss = \u001b[38;5;28mself\u001b[39m.precision_plugin.pre_backward(closure_loss, \u001b[38;5;28mself\u001b[39m.lightning_module)\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprecision_plugin\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlightning_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    215\u001b[39m closure_loss = \u001b[38;5;28mself\u001b[39m.precision_plugin.post_backward(closure_loss, \u001b[38;5;28mself\u001b[39m.lightning_module)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py:73\u001b[39m, in \u001b[36mPrecision.backward\u001b[39m\u001b[34m(self, tensor, model, optimizer, *args, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Performs the actual backpropagation.\u001b[39;00m\n\u001b[32m     63\u001b[39m \n\u001b[32m     64\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     71\u001b[39m \n\u001b[32m     72\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pytorch_lightning/core/module.py:1097\u001b[39m, in \u001b[36mLightningModule.backward\u001b[39m\u001b[34m(self, loss, *args, **kwargs)\u001b[39m\n\u001b[32m   1096\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1097\u001b[39m     \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 67\u001b[39m\n\u001b[32m     65\u001b[39m model = TCNModel(**model_params)\n\u001b[32m     66\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining model...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_scaled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_series\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_scaled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     71\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[38;5;66;03m# 7. Load best checkpoint\u001b[39;00m\n\u001b[32m     74\u001b[39m model = TCNModel.load_from_checkpoint(model_name=MODEL_NAME, best=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/darts/utils/torch.py:80\u001b[39m, in \u001b[36mrandom_method.<locals>.decorator\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m fork_rng():\n\u001b[32m     79\u001b[39m     manual_seed(\u001b[38;5;28mself\u001b[39m._random_instance.randint(\u001b[32m0\u001b[39m, high=MAX_TORCH_SEED_VALUE))\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdecorated\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/darts/models/forecasting/torch_forecasting_model.py:842\u001b[39m, in \u001b[36mTorchForecastingModel.fit\u001b[39m\u001b[34m(self, series, past_covariates, future_covariates, val_series, val_past_covariates, val_future_covariates, trainer, verbose, epochs, max_samples_per_ts, dataloader_kwargs, sample_weight, val_sample_weight)\u001b[39m\n\u001b[32m    836\u001b[39m \u001b[38;5;66;03m# call super fit only if user is actually fitting the model\u001b[39;00m\n\u001b[32m    837\u001b[39m \u001b[38;5;28msuper\u001b[39m().fit(\n\u001b[32m    838\u001b[39m     series=seq2series(series),\n\u001b[32m    839\u001b[39m     past_covariates=seq2series(past_covariates),\n\u001b[32m    840\u001b[39m     future_covariates=seq2series(future_covariates),\n\u001b[32m    841\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m842\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_from_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/darts/utils/torch.py:80\u001b[39m, in \u001b[36mrandom_method.<locals>.decorator\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m fork_rng():\n\u001b[32m     79\u001b[39m     manual_seed(\u001b[38;5;28mself\u001b[39m._random_instance.randint(\u001b[32m0\u001b[39m, high=MAX_TORCH_SEED_VALUE))\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdecorated\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/darts/models/forecasting/torch_forecasting_model.py:1022\u001b[39m, in \u001b[36mTorchForecastingModel.fit_from_dataset\u001b[39m\u001b[34m(self, train_dataset, val_dataset, trainer, verbose, epochs, dataloader_kwargs)\u001b[39m\n\u001b[32m    969\u001b[39m \u001b[38;5;129m@random_method\u001b[39m\n\u001b[32m    970\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mfit_from_dataset\u001b[39m(\n\u001b[32m    971\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    977\u001b[39m     dataloader_kwargs: Optional[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    978\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mTorchForecastingModel\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    979\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    980\u001b[39m \u001b[33;03m    Train the model with a specific :class:`darts.utils.data.TrainingDataset` instance.\u001b[39;00m\n\u001b[32m    981\u001b[39m \u001b[33;03m    These datasets implement a PyTorch ``Dataset``, and specify how the target and covariates are sliced\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1020\u001b[39m \u001b[33;03m        Fitted model.\u001b[39;00m\n\u001b[32m   1021\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1022\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setup_for_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m            \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[43m            \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdataloader_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataloader_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1032\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/darts/models/forecasting/torch_forecasting_model.py:1211\u001b[39m, in \u001b[36mTorchForecastingModel._train\u001b[39m\u001b[34m(self, trainer, model, train_loader, val_loader)\u001b[39m\n\u001b[32m   1208\u001b[39m \u001b[38;5;28mself\u001b[39m.load_ckpt_path = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1210\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._requires_training:\n\u001b[32m-> \u001b[39m\u001b[32m1211\u001b[39m     \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1212\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1213\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1214\u001b[39m \u001b[43m        \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1215\u001b[39m \u001b[43m        \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1216\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1217\u001b[39m \u001b[38;5;28mself\u001b[39m.model = model\n\u001b[32m   1218\u001b[39m \u001b[38;5;28mself\u001b[39m.trainer = trainer\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:561\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    559\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    560\u001b[39m \u001b[38;5;28mself\u001b[39m.should_stop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:65\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[32m     64\u001b[39m         launcher.kill(_get_sigkill_signal())\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[43mexit\u001b[49m(\u001b[32m1\u001b[39m)\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[32m     68\u001b[39m     _interrupt(trainer, exception)\n",
      "\u001b[31mNameError\u001b[39m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from darts import TimeSeries\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.models import TCNModel\n",
    "from darts.utils.callbacks import TFMProgressBar\n",
    "from darts.utils.missing_values import fill_missing_values\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Configuration\n",
    "DATA_PATH = '/home/saihan/New folder/data/fear/fear_1.npy'\n",
    "TRAIN_SPLIT = 0.8  # 80% for training, 20% for validation\n",
    "MODEL_NAME = 'TCN_EMG'\n",
    "\n",
    "# 1. Load EMG data\n",
    "emg_data = np.load(DATA_PATH)\n",
    "print(f\"Loaded EMG data shape: {emg_data.shape}\")  # Should be (n_timesteps, 8)\n",
    "\n",
    "# 2. Preprocess data\n",
    "# Replace placeholder values with NaNs\n",
    "emg_data[emg_data == -1000] = np.nan\n",
    "\n",
    "# Create DataFrame with time index\n",
    "time_index = pd.RangeIndex(start=0, stop=len(emg_data), step=1)\n",
    "df = pd.DataFrame(emg_data, index=time_index)\n",
    "\n",
    "# Create TimeSeries from DataFrame\n",
    "series = TimeSeries.from_dataframe(df)\n",
    "\n",
    "# Handle missing values\n",
    "series = fill_missing_values(series, method='linear')\n",
    "print(\"Missing values filled\")\n",
    "\n",
    "# 3. Split data\n",
    "train_size = int(len(series) * TRAIN_SPLIT)\n",
    "train, val = series[:train_size], series[train_size:]\n",
    "\n",
    "# 4. Scale data\n",
    "scaler = Scaler()\n",
    "train_scaled = scaler.fit_transform(train)\n",
    "val_scaled = scaler.transform(val)\n",
    "series_scaled = scaler.transform(series)\n",
    "\n",
    "# 5. Configure model parameters\n",
    "model_params = {\n",
    "    'input_chunk_length': 1024,      # Historical window size\n",
    "    'output_chunk_length': 128,      # Forecast horizon\n",
    "    'n_epochs': 100,\n",
    "    'dropout': 0.2,\n",
    "    'dilation_base': 2,\n",
    "    'weight_norm': True,\n",
    "    'kernel_size': 5,\n",
    "    'num_filters': 8,                # Matches 8 EMG channels\n",
    "    'random_state': 42,\n",
    "    'save_checkpoints': True,\n",
    "    'model_name': MODEL_NAME,\n",
    "    'force_reset': True,\n",
    "    'pl_trainer_kwargs': {\n",
    "        'accelerator': 'cpu',\n",
    "        'callbacks': [TFMProgressBar(enable_train_bar_only=True)]\n",
    "    }\n",
    "}\n",
    "\n",
    "# 6. Create and train model\n",
    "model = TCNModel(**model_params)\n",
    "print(\"Training model...\")\n",
    "model.fit(\n",
    "    series=train_scaled,\n",
    "    val_series=val_scaled,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 7. Load best checkpoint\n",
    "model = TCNModel.load_from_checkpoint(model_name=MODEL_NAME, best=True)\n",
    "\n",
    "# 8. Generate forecasts\n",
    "print(\"Generating forecasts...\")\n",
    "forecast = model.predict(\n",
    "    n=500,                          # Forecast 500 steps into future\n",
    "    series=train_scaled\n",
    ")\n",
    "\n",
    "# 9. Inverse scaling for visualization\n",
    "forecast_inv = scaler.inverse_transform(forecast)\n",
    "val_inv = scaler.inverse_transform(val_scaled)\n",
    "\n",
    "# 10. Plot results\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot first channel only for clarity\n",
    "channel_idx = 0\n",
    "plt.plot(val_inv.time_index, val_inv.univariate_values()[:, channel_idx], label='Actual')\n",
    "plt.plot(forecast_inv.time_index, forecast_inv.univariate_values()[:, channel_idx], label='Forecast')\n",
    "\n",
    "plt.title(f'EMG Signal Forecasting - Channel {channel_idx+1}')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
